{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Long notebook assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Cognitive Commanders</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td align=\"center\">\n",
    "            <strong>Petter Dalhaug (528276)</strong><br>\n",
    "        </td>\n",
    "        <td align=\"center\">\n",
    "            <strong>Mathias Otnes (563940)</strong><br>\n",
    "        </td>\n",
    "        <td align=\"center\">\n",
    "            <strong>Christoffer Roelofsen (544069)</strong><br>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"./assets/petter.png\" width=\"100%\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"./assets/mathias.png\" width=\"100%\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"./assets/christoffer.png\" width=\"100%\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Domain Knowledge**\n",
    "After reading up on solar panel performance, there were som obvious factors that we could take advantage of based on our features. There were also some factors that would be more difficult for us to pick up on. For example panel maintanance and other non-weather related features would not be something we could get from our data. This was the most important factors based on the article referenced in the sources:\n",
    "\n",
    "### **Radiation**\n",
    "\n",
    "(PV) production is highly sensitive to the amount of accessible solar energy that falls directly on the module, with specific reference to a loss in efficiency when there is a deviation from the direct component of solar irradiation. This directly relates to solar radiation, indicating that optimal PV system performance is closely tied to receiving direct sunlight.\n",
    "\n",
    "### **Sun alignment**\n",
    "\n",
    "PV output is significantly affected by the alignment to the sun, with even minor deviations causing measurable efficiency losses.\n",
    "\n",
    "### **Temperature**\n",
    "\n",
    "PV module efficiency decreases as temperatures rise, emphasizing the need for cooling strategies.\n",
    "\n",
    "### **Dust**\n",
    "\n",
    "Dust accumulation on PV modules affects energy output over time, reducing transmittance and thus efficiency, if not regularly cleaned. Dust could also be related to wind, making that an interesting feature\n",
    "\n",
    "### **Environmental factors**\n",
    "\n",
    "The tilt angle of panels, local weather conditions like rain and wind speed, and environmental cleanliness are vital in maintaining or improving a module's performance.\n",
    "\n",
    "### **Wind**\n",
    "\n",
    "While wind can cool PV modules and improve efficiency, its effectiveness varies significantly with location and ambient temperature conditions.\n",
    "\n",
    "### **Humidity**\n",
    "\n",
    "Environments with high temperatures and humidity levels above 70% markedly decrease solar cell efficiency.\n",
    "\n",
    "\n",
    "A lot of these factors outlined here are information we have in our features, and what is interesting is that the combination of some speficic features seem to be important based on the article. \n",
    "\n",
    "\n",
    "When it came to understanding how the data was generated, we didnt spend that much time investigating. This was not the most important information in our eyes. A simple question to chatgpt gave us this answer:\n",
    "\n",
    "\"The data for predicting solar energy production in a Kaggle competition is likely generated through a combination of observational measurements, weather modeling, and solar radiation simulations. Here's a brief overview of possible sources for each type of data:\n",
    "\n",
    "1. **PV Measurement**: Actual recorded output from photovoltaic systems.\n",
    "2. **Atmospheric Conditions**: 'Absolute_humidity_2m_gm3', 'air_density_2m_kgm3', 'dew_point_2m_K', 'msl_pressure_hPa', 'pressure_100m_hPa', 'pressure_50m_hPa', 'relative_humidity_1000hPa_p', 'sfc_pressure_hPa', 'visibility_m' are typically derived from weather stations and atmospheric models.\n",
    "3. **Radiation Data**: 'Clear_sky_rad_W', 'diffuse_rad_W', 'direct_rad_W', 'diffuse_rad_1h_J', 'direct_rad_1h_J' could be obtained from satellite observations and radiative transfer models that estimate solar radiation reaching the ground.\n",
    "4. **Cloud Cover**: 'Effective_cloud_cover_p', 'total_cloud_cover_p' might come from satellite imagery or weather forecast models.\n",
    "5. **Elevation Data**: 'Elevation_m' is geographical data, which can influence the microclimate and sun exposure of the location.\n",
    "6. **Sun Position**: 'Sun_azimuth_d', 'sun_elevation_d' are calculated based on the geographical location and time of the year.\n",
    "7. **Wind Conditions**: 'Wind_speed_10m_ms', 'wind_speed_u_10m_ms', 'wind_speed_v_10m_ms' are obtained from meteorological models or local measurements.\n",
    "8. **Snow Water Equivalent**: 'Snow_water_kgm2' indicates the water content in snow, measured via sensors or estimated through models.\n",
    "9. **Temporal Data**: 'Month', 'year', 'time_of_day' are time stamps for the data points, crucial for correlating weather patterns with solar energy production.\n",
    "10. **Shadowing and Daylight Index**: 'Is_day_idx', 'is_in_shadow_idx' indicate whether it's day and if the location is shadowed, which might be derived from sun position algorithms or local topographical data.\n",
    "\n",
    "The datasets are often a hybrid of in situ measurements from ground weather stations, satellite data, and numerical weather prediction models.\"(GPT4, 2023)\n",
    "\n",
    "The most intersting thing here are the geographical related features, which we could use to estimate where the data is from. After looking in to this we were pretty sure it was from Norway. \n",
    "\n",
    "\n",
    "sources:\n",
    "\n",
    " Jathar, L. D., Ganesan, S., Awasarmol, U., Nikam, K., Shahapurkar, K., Soudagar, M. E. M., Fayaz, H., El-Shafay, A. S., Kalam, M. A., Bouadila, S., Baddadi, S., Tirth, V., Nizami, A. S., Lam, S. S., & Rehan, M. (Year). Comprehensive review of environmental factors influencing the performance of photovoltaic panels: Concern over emissions at various phases throughout the lifecycle. Environmental Pollution, Volume 326. DOI or URL https://www.sciencedirect.com/science/article/pii/S0269749123004761?via%3Dihub#sec6\n",
    "\n",
    " OpenAI. (2023). ChatGPT-4 [Chatbot]. Available from https://chat.openai.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EDA**\n",
    "\n",
    "The first thing we did was to analyse the correlation between all the features and the target.\n",
    "![Correlation](./assets/correlations.png)\n",
    "\n",
    "After this, we went through all the features to see if we could spot any patterns. Note that some columns are engineered as this was an iterative process. This is one of many pairplots we went through for analysing. We went through all the features.\n",
    "\n",
    "![Pairplot with solar columns](./assets/solar_columns.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pv_columns\n",
    "\n",
    "- `total_radiation` has a linear relationship with `pv_measurement`.\n",
    "- `date_forecast_fft_amplitude` and `date_forecast_fft_phase` look pretty useless. \n",
    "- `total_radiation_rate_of_change` seems to not tell anything about `pv_measurement`.\n",
    "- `total_radiation_rollinig_avg_3` is very similar to `total_radiation`, and keeping both would likelly lead to multicollinearity.\n",
    "\n",
    "<strong>`total_radiation` is the only feature that should be kept, and further feature engineering is probaly not necessary</strong>\n",
    "\n",
    "## snow_columns\n",
    "\n",
    "- All the snow features have some negative correlation between with the `pv_measurement`. Most of them have mostly zeroes.\n",
    "- `snow_accumulation` has good correlation with all snow features, and is a good representative to them all.\n",
    "\n",
    "<strong>Use `snow_accumulation` as the only snow feature</strong>\n",
    "\n",
    "## pressure_columns\n",
    "\n",
    "- The values are very big, and looks like they're all constant for the different `pv_measurement` values, but normalizing these can propably lead so show some relation.\n",
    "\n",
    "<strong>These features need some scaling</strong>\n",
    "\n",
    "## cloud_columns\n",
    "\n",
    "- `effective_cloud_cover:p` and `total_cloud_cover:p` has a very high correlation with eachother, but they seem random in relation to `pv_measurement`. These should be investigated to see if they can show a non-random pattern when combined with other features. \n",
    "- `cloud_base_agl:m` has a slightly negative correlation with `pv_measurement`, and not many relationships to other features. This should be investigated.\n",
    "- `super_cooled_liquid_water:kgm2` has a negative correlation with `pv_measurement`, and slight positive correlation with `effective_cloud_cover:p` and `total_cloud_cover:p` which can hint of a relationship between cloud cover and when the liquid is used. Maybe this can be used to find a relationship between the seemingly random cloud covers and `pv_measurement`\n",
    "\n",
    "<strong>Only one of `effective_cloud_cover:p` and `total_cloud_cover:p` should be used, but should be combined with other features to reveal a relationship. `cloud_base_agl:m` can maybe get used, but propably not the best feature without engineering. `super_cooled_liquid_water:kgm2` is a good feature. </strong>\n",
    "\n",
    "## temperature_columns\n",
    "\n",
    "- `t_1000hPa:K` and `dew_point_2m:K` may have a correlation with `pv_measurement`, but they need scaling in order to reveal this.\n",
    "- `temp_dewpoint_diff` seems to have correlation with `pv_measurement`, but this can be just because the temperatures has been scaled because `t_1000hPa:K` and `dew_point_2m:K` have similar scales which leads their difference to be pretty standardized. The lagged feature `temp_dewpoint_diff_lag_-4` has high correlation with `temp_dewpoint_diff`, and only one should be kept. It's likelly that the lagged feature is artificially more correlated to `pv_measurement`, and should be removed. \n",
    "- `t_1000hPa:K_rate_of_change` seems to have a slight positive correlation to `pv_measurement`, and no correlation with other features, and should be kept, but some engineering for scaling is maybe necessary.\n",
    "- `t_1000hPa:K` and `dew_point_2m:K` have some datapoints in 0 kelvin, which should be removed.\n",
    "\n",
    "<strong>Scale the features `t_1000hPa:K_rate_of_change`, `t_1000hPa:K` and `dew_point_2m:K`. Remove 0 kelvin datapoints, and figure out if we need both `t_1000hPa:K` and `dew_point_2m:K` or if we should only choose one.</strong>\n",
    "\n",
    "## humidity_columns\n",
    "\n",
    "- Roughly all high values of `pv_measurment` is when `dew_or_rime:idx` is 0, and this can maybe be engineered a bit, it can maybe be used as a \"filter\" for high measurements. \n",
    "- `relative_humidity_1000hPa:p` and `absolute_humidity_1000hPa:p` doesn't have too much correlation, both can be kept, but `relative_humidity_1000hPa:p` may encode the temperature dependency, which can be more beneficial. The both seem to be uncorrelated to `pv_measurement`, but an implicit correlation should be searched for. \n",
    "- All features mulitplied with temperature is almost perfectly correlated with the original feature, be aware of this. Scale the temperature before making the interaction feature, or don't include the interaction features. \n",
    "- Rolling averages don't seem to have much effect.\n",
    "\n",
    "<strong>Search for a combined feature including `relative_humidity_1000hPa:p` and/or `absolute_humidity_1000hPa:p` for revealing a implicit correlation.</strong>\n",
    "\n",
    "## wind_columns\n",
    "\n",
    "- All wind speed columns seems very correlated to `average_wind_speed`, which has the best correlation with `pv_measurement`.\n",
    "- `wind_speed_w_1000hPa:ms` seems useless.\n",
    "- `wind_vector_magnitude` is similar to `average_wind_speed` and correlated, but slightly less correlated to `pv_measurement`.\n",
    "\n",
    "<strong>Only keep `average_wind_speed`.</strong>\n",
    "\n",
    "## solar_columns (from picture)\n",
    "\n",
    "- `sun_elevation:d` has a high correlation with `pv_measurement`. All the measurements are 0 when `sun_elevation:d` are 0 and less. Some engineering may be necessary, it whould have a lot of weight when the elevation is 0 or less, because it shouldn't be possible with positive `pv_measurments` without sun.\n",
    "- `sun_azimuth:d` has a bell curve correlation with `pv_measurement`, and could maybe benefit from some engineering. It's a very clear pattern. It has similar correlation to a lot of the other radiation features.\n",
    "- `sun_elevation:dfft_amplitude` seems bad, and has values close to infinity. \n",
    "- `sun_elevation:dfft_phase` has some strange patterns, but is seemingly random regarding `pv_measurement`, and should be dropped.\n",
    "- `sun_elevation_rolling_avg_6` looses information about the measurement being 0 when there is no sun. It's very correlated with `sun_elevation:d`, and it should be removed. \n",
    "- `sun_elevation_direct_rad_interaction` seems very nicely correlated with `pv_measurement`. I would like to see what happens if `sun_elevation:d` is strictly positive before combining. This interaction feature should also be scaled down a bit, and it could possibly use `total_radiation` instead of `direct_rad:W`.\n",
    "- `clear_sky_rad:W` is very correlated with `pv_measurement`, but also to `clear_sky_energy_1h:J`, and only one of them should be kept. It seems like it can't be larger than `direct_rad:W`, so maybe an interaction feature here could be interesting. \n",
    "- `direct_rad:W` and `direct_rad_1h:J` is very correlated, only one should be kept, but they have good correlation with `pv_measurement`.\n",
    "- `direct_rad:W_rate_of_change` seems uncorrelated to `pv_measurement`.\n",
    "- `diffuse_rad:W` seems somewhat uncorrelated to `direct_rad:W`, but very correlated to `pv_measurement`. It's very correlated to `diffuse_rad_1h:J`, and only one of them should be kept. \n",
    "- `diffuse_rad:W_rate_of_change` seems uncorrelated to `pv_measurement`.\n",
    "\n",
    "<strong>Experimant with `sun_elevation:d` and `sun_azimuth`. Remove fft features and rolling averages. Experiment with interaction features with `sun_elevation:d`. Experiment with interaction between `clear_sky_energy_1h:J`, `clear_sky_rad:W` and other radiation features. Remove all rate of change features. Test what is best between `total_radiation` and having both `diffuse_rad:W` and `direct_rad:W`</strong>\n",
    "\n",
    "## visibility_columns\n",
    "\n",
    "- `visibility:m` seems uncorrelated to `pv_measurement`, but maybe it can be used as an interaction features.\n",
    "- `ceiling_height_agl:m` seems to always be larger than `cloud_base_agl:m`, but both of them seem uncorrelated to pv_measurement. Maybe a boolean value can be extracted from these to indicate whether or not there is clouds.\n",
    "- `is_day:idx` and `is_in_shadow:idx` has all the high `pv_measurement` values where you expect them, but it doesn't seem to provide a lot of info. Maybe it can be used in another feature.\n",
    "\n",
    "<strong>Experiment with `visibility:m`, `ceiling_height_agl:m`, `cloud_base_agl:m`, `is_day:idx` and `is_in_shadow:idx`. They all seem useless on their own.</strong>\n",
    "\n",
    "## precipitation_columns\n",
    "\n",
    "- `rain_water:kgm2` seems correlated to `pv_measurement`, and should be explored. \n",
    "- `precip_5min:mm` seems similar to `rain_water:kgm2`, but with less information. It can maybe be combined with `precip_type_5min:idx` to reveal a correlation.\n",
    "- The rest of the features doesn't seem to provide much info.\n",
    "\n",
    "<strong>Explore the combination of `precip_5min:mm` and `precip_type_5min:idx`. Maybe try to include `rain_water:kgm2`.</strong>\n",
    "\n",
    "## time_lagged_columns\n",
    "\n",
    "<strong>These all seem to include artificial correlations, and should likelly not be included.</strong>\n",
    "\n",
    "## miscellaneous_columns\n",
    "\n",
    "- `elevation:m` has some measurements that deviates. What's the deal with that?\n",
    "- `month` seems to show a clear trend, maybe some engineering to get the relationship to get caught by the model.\n",
    "- `observed` is uncorrelated, but maybe it can be combined with another feature.\n",
    "\n",
    "<strong>Investigate ways to empasize the relationship between `month` and `pv_measurement`. Maybe explore combinatied features with `observed`.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Multicollinearity**\n",
    "Heatmap for finding correlation between columns. We aim to exclude columns that are very correlated with eachother because this may confuse the model on the underlying dependencies between the features and the target.\n",
    "![Heatmap](./assets/heatmap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lagged features**\n",
    "\n",
    "We also investigated all the features for potential lagged correlation with the target by checking the cross-correlation between all the features and the target. This is one of the lagged correlations we found between the target and pressure. It's plotted with a confidence-interval of 95%.\n",
    "![Lagged pressure](./assets/lag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extra comments**\n",
    "\n",
    "- elevation:m seemed to be constant on the different locations, and we chose to remove it. \n",
    "- Most of the data seemed intuitive, e.g when sun_elevation:d is less than 0, pv_measurement is 0. And pv_measurement is the most when the sun is at it's highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing**\n",
    "\n",
    "Our aggregation methods where found through experimentation, domain knowledge and by exploring correlations between the different parts of the hours and the target for the corresponding hour. The plot is hard to interpret so we left it out of the report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data to hourly with some aggregation methods for each column\n",
    "\n",
    "aggregation_methods = {\n",
    "    'date_forecast': 'first',\n",
    "    'diffuse_rad:W': 'sum',\n",
    "    'direct_rad:W': 'last',\n",
    "    'clear_sky_rad:W': 'sum',\n",
    "    'diffuse_rad_1h:J': 'last',\n",
    "    'direct_rad_1h:J': 'last',\n",
    "    'clear_sky_energy_1h:J': 'last',\n",
    "    'absolute_humidity_2m:gm3': 'mean',\n",
    "    'air_density_2m:kgm3': 'mean',\n",
    "    'ceiling_height_agl:m': 'max',\n",
    "    'cloud_base_agl:m': 'mean',\n",
    "    'dew_or_rime:idx': 'min',\n",
    "    'dew_point_2m:K': 'mean',\n",
    "    'effective_cloud_cover:p': 'sum',\n",
    "    'elevation:m': 'first',\n",
    "    'fresh_snow_12h:cm': 'max',\n",
    "    'fresh_snow_1h:cm': 'sum',\n",
    "    'fresh_snow_24h:cm': 'max',\n",
    "    'fresh_snow_3h:cm': 'max',\n",
    "    'fresh_snow_6h:cm': 'max',\n",
    "    'is_day:idx': 'max',\n",
    "    'is_in_shadow:idx': 'max',\n",
    "    'msl_pressure:hPa': 'mean',\n",
    "    'precip_5min:mm': 'sum',\n",
    "    'precip_type_5min:idx': 'sum',\n",
    "    'pressure_100m:hPa': 'mean',\n",
    "    'pressure_50m:hPa': 'mean',\n",
    "    'prob_rime:p': 'max',\n",
    "    'rain_water:kgm2': 'sum',\n",
    "    'relative_humidity_1000hPa:p': 'mean',\n",
    "    'sfc_pressure:hPa': 'mean',\n",
    "    'snow_density:kgm3': 'mean',\n",
    "    'snow_depth:cm': 'max',\n",
    "    'snow_drift:idx': 'max',\n",
    "    'snow_melt_10min:mm': 'sum',\n",
    "    'snow_water:kgm2': 'sum',\n",
    "    'sun_azimuth:d': 'first',\n",
    "    'sun_elevation:d': 'sum',\n",
    "    'super_cooled_liquid_water:kgm2': 'sum',\n",
    "    't_1000hPa:K': 'mean',\n",
    "    'total_cloud_cover:p': 'mean',\n",
    "    'visibility:m': 'mean',\n",
    "    'wind_speed_10m:ms': 'mean',\n",
    "    'wind_speed_u_10m:ms': 'mean',\n",
    "    'wind_speed_v_10m:ms': 'mean',\n",
    "    'wind_speed_w_1000hPa:ms': 'mean',\n",
    "    'cloud_base_agl:m': 'max',\n",
    "    'snow_density:kgm3': 'mean'\n",
    "}\n",
    "\n",
    "\n",
    "# Read in the data\n",
    "x_target_A = pd.read_parquet('./data/A/train_targets.parquet')\n",
    "x_train_obs_A = pd.read_parquet('./data/A/X_train_observed.parquet')\n",
    "x_train_est_A = pd.read_parquet('./data/A/X_train_estimated.parquet')\n",
    "x_test_est_A = pd.read_parquet('./data/A/X_test_estimated.parquet')\n",
    "\n",
    "x_target_B = pd.read_parquet('./data/B/train_targets.parquet')\n",
    "x_train_obs_B = pd.read_parquet('./data/B/X_train_observed.parquet')\n",
    "x_train_est_B = pd.read_parquet('./data/B/X_train_estimated.parquet')\n",
    "x_test_est_B = pd.read_parquet('./data/B/X_test_estimated.parquet')\n",
    "\n",
    "x_target_C = pd.read_parquet('./data/C/train_targets.parquet')\n",
    "x_train_obs_C = pd.read_parquet('./data/C/X_train_observed.parquet')\n",
    "x_train_est_C = pd.read_parquet('./data/C/X_train_estimated.parquet')\n",
    "x_test_est_C = pd.read_parquet('./data/C/X_test_estimated.parquet')\n",
    "\n",
    "# Rename time to date_forecast in target\n",
    "x_target_A.rename(columns={'time': 'date_forecast'}, inplace=True)\n",
    "x_target_B.rename(columns={'time': 'date_forecast'}, inplace=True)\n",
    "x_target_C.rename(columns={'time': 'date_forecast'}, inplace=True)\n",
    "\n",
    "# Fix missing data for test set. Assumin NaN means 0 in these categories\n",
    "x_test_est_A['effective_cloud_cover:p'] = x_test_est_A['effective_cloud_cover:p'].fillna(0)\n",
    "x_test_est_B['effective_cloud_cover:p'] = x_test_est_B['effective_cloud_cover:p'].fillna(0)\n",
    "x_test_est_C['effective_cloud_cover:p'] = x_test_est_C['effective_cloud_cover:p'].fillna(0)\n",
    "\n",
    "x_test_est_A['total_cloud_cover:p'] = x_test_est_A['total_cloud_cover:p'].fillna(0)\n",
    "x_test_est_B['total_cloud_cover:p'] = x_test_est_B['total_cloud_cover:p'].fillna(0)\n",
    "x_test_est_C['total_cloud_cover:p'] = x_test_est_C['total_cloud_cover:p'].fillna(0)\n",
    "\n",
    "x_test_est_A['cloud_base_agl:m'] = x_test_est_A['cloud_base_agl:m'].fillna(0)\n",
    "x_test_est_B['cloud_base_agl:m'] = x_test_est_B['cloud_base_agl:m'].fillna(0)\n",
    "x_test_est_C['cloud_base_agl:m'] = x_test_est_C['cloud_base_agl:m'].fillna(0)\n",
    "\n",
    "x_test_est_A['ceiling_height_agl:m'] = x_test_est_A['ceiling_height_agl:m'].fillna(0)\n",
    "x_test_est_B['ceiling_height_agl:m'] = x_test_est_B['ceiling_height_agl:m'].fillna(0)\n",
    "x_test_est_C['ceiling_height_agl:m'] = x_test_est_C['ceiling_height_agl:m'].fillna(0)\n",
    "\n",
    "x_test_est_A['snow_density:kgm3'] = x_test_est_A['snow_density:kgm3'].fillna(0)\n",
    "x_test_est_B['snow_density:kgm3'] = x_test_est_B['snow_density:kgm3'].fillna(0)\n",
    "x_test_est_C['snow_density:kgm3'] = x_test_est_C['snow_density:kgm3'].fillna(0)\n",
    "\n",
    "x_test_est_A['snow_drift:idx'] = x_test_est_A['snow_drift:idx'].fillna(0)\n",
    "x_test_est_B['snow_drift:idx'] = x_test_est_B['snow_drift:idx'].fillna(0)\n",
    "x_test_est_C['snow_drift:idx'] = x_test_est_C['snow_drift:idx'].fillna(0)\n",
    "\n",
    "# Resample\n",
    "x_train_obs_A_resampled = x_train_obs_A.groupby(pd.Grouper(key='date_forecast', freq='1H')).aggregate(aggregation_methods)\n",
    "x_train_est_A_resampled = x_train_est_A.groupby(pd.Grouper(key='date_forecast', freq='1H')).aggregate(aggregation_methods)\n",
    "x_test_est_A_resampled = x_test_est_A.groupby(pd.Grouper(key='date_forecast', freq='1H')).aggregate(aggregation_methods)\n",
    "\n",
    "x_train_obs_B_resampled = x_train_obs_B.groupby(pd.Grouper(key='date_forecast', freq='1H')).aggregate(aggregation_methods)\n",
    "x_train_est_B_resampled = x_train_est_B.groupby(pd.Grouper(key='date_forecast', freq='1H')).aggregate(aggregation_methods)\n",
    "x_test_est_B_resampled = x_test_est_B.groupby(pd.Grouper(key='date_forecast', freq='1H')).aggregate(aggregation_methods)\n",
    "\n",
    "x_train_obs_C_resampled = x_train_obs_C.groupby(pd.Grouper(key='date_forecast', freq='1H')).aggregate(aggregation_methods)\n",
    "x_train_est_C_resampled = x_train_est_C.groupby(pd.Grouper(key='date_forecast', freq='1H')).aggregate(aggregation_methods)\n",
    "x_test_est_C_resampled = x_test_est_C.groupby(pd.Grouper(key='date_forecast', freq='1H')).aggregate(aggregation_methods)\n",
    "\n",
    "# Merge\n",
    "split_value = x_train_est_A['date_forecast'].iloc[0]\n",
    "split_index = x_target_A[x_target_A['date_forecast'] == split_value].index[0]\n",
    "\n",
    "x_target_obs_A = x_target_A.iloc[:split_index]\n",
    "x_target_est_A = x_target_A.iloc[split_index:]\n",
    "\n",
    "obs_A = x_train_obs_A_resampled.merge(x_target_obs_A, left_index=True, right_on='date_forecast')\n",
    "est_A = x_train_est_A_resampled.merge(x_target_est_A, left_index=True, right_on='date_forecast')\n",
    "\n",
    "split_value = x_train_est_B['date_forecast'].iloc[0]\n",
    "split_index = x_target_B[x_target_B['date_forecast'] == split_value].index[0]\n",
    "\n",
    "x_target_obs_B = x_target_B.iloc[:split_index]\n",
    "x_target_est_B = x_target_B.iloc[split_index:]\n",
    "\n",
    "obs_B = x_train_obs_B_resampled.merge(x_target_obs_B, left_index=True, right_on='date_forecast')\n",
    "est_B = x_train_est_B_resampled.merge(x_target_est_B, left_index=True, right_on='date_forecast')\n",
    "\n",
    "split_value = x_train_est_C['date_forecast'].iloc[0]\n",
    "split_index = x_target_C[x_target_C['date_forecast'] == split_value].index[0]\n",
    "\n",
    "x_target_obs_C = x_target_C.iloc[:split_index]\n",
    "x_target_est_C = x_target_C.iloc[split_index:]\n",
    "\n",
    "obs_C = x_train_obs_C_resampled.merge(x_target_obs_C, left_index=True, right_on='date_forecast')\n",
    "est_C = x_train_est_C_resampled.merge(x_target_est_C, left_index=True, right_on='date_forecast')\n",
    "\n",
    "# Keep date_forecast in test dfs\n",
    "test_A = x_test_est_A_resampled\n",
    "test_B = x_test_est_B_resampled\n",
    "test_C = x_test_est_C_resampled\n",
    "\n",
    "# Drop all the NaNs\n",
    "test_A = test_A.dropna()\n",
    "test_B = test_B.dropna()\n",
    "test_C = test_C.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`add_experimental_features()` is a set of features with different combinations of features that we thought were smart based on domain knowledge and experimentation. Some of these has more correlation with the target than the base features such as `total_radiation:W`. We have also done some engineering based on the EDA from earlier such as using the temperature in Celsius instead of Kelvin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_experimental_features(df):\n",
    "    \"\"\"\n",
    "    Experimental feature engineering.\n",
    "    \"\"\"\n",
    "\n",
    "    # Radiation Features\n",
    "    df['total_radiation:W'] = df['direct_rad:W'] + df['diffuse_rad:W']\n",
    "    df['total_radiation_1h:J'] = df['direct_rad_1h:J'] + df['diffuse_rad_1h:J']\n",
    "    df['rad_diff:W'] = df['direct_rad:W'] - df['diffuse_rad:W']\n",
    "    df['rad_diff_1h:J'] = df['direct_rad_1h:J'] - df['diffuse_rad_1h:J']\n",
    "    df['diffuse_direct_ratio'] = df['diffuse_rad:W'] / df['direct_rad:W']\n",
    "\n",
    "    # Temperature and Pressure Features\n",
    "    df['temp_dewpoint_diff'] = df['t_1000hPa:K'] - df['dew_point_2m:K']\n",
    "    df['pressure_gradient'] = df['pressure_100m:hPa'] - df['pressure_50m:hPa']\n",
    "    df['t_1000hPa:C'] = df['t_1000hPa:K'] - 273.15\n",
    "    df['dew_point_2m:C'] = df['dew_point_2m:K'] - 273.15\n",
    "    df['msl_pressure:hPa_scaled'] = MinMaxScaler().fit_transform(df['msl_pressure:hPa'].values.reshape(-1, 1))\n",
    "    df['sfc_pressure:hPa_scaled'] = MinMaxScaler().fit_transform(df['sfc_pressure:hPa'].values.reshape(-1, 1))\n",
    "\n",
    "    # Wind Features\n",
    "    df['wind_vector_magnitude'] = (df['wind_speed_u_10m:ms']**2 + df['wind_speed_v_10m:ms']**2 + df['wind_speed_w_1000hPa:ms']**2)**0.5\n",
    "    df['average_wind_speed'] = (df['wind_speed_10m:ms'] + df['wind_speed_u_10m:ms']) / 2\n",
    "\n",
    "    # Cloud and Snow Features\n",
    "    df['cloud_humidity_product'] = df['total_cloud_cover:p'] * df['absolute_humidity_2m:gm3']\n",
    "    df['snow_accumulation'] = df[['fresh_snow_24h:cm', 'fresh_snow_12h:cm', 'fresh_snow_6h:cm', 'fresh_snow_3h:cm', 'fresh_snow_1h:cm']].sum(axis=1)\n",
    "\n",
    "    # Interaction between radiation and cloud cover\n",
    "    df['radiation_cloud_interaction'] = df['direct_rad:W'] * df['effective_cloud_cover:p']\n",
    "\n",
    "    # Interaction between temperature and radiation (considering that high temperature may reduce efficiency)\n",
    "    df['temp_rad_interaction'] = df['t_1000hPa:K'] * df['total_radiation:W']\n",
    "\n",
    "    # Interaction between wind cooling effect and temperature\n",
    "    df['wind_temp_interaction'] = df['average_wind_speed'] * df['t_1000hPa:K']\n",
    "\n",
    "    # Interaction between humidity and temperature\n",
    "    df['humidity_temp_interaction'] = df['absolute_humidity_2m:gm3'] * df['t_1000hPa:K']\n",
    "\n",
    "    # Interaction between humidity and radiation\n",
    "    df['sun_elevation_direct_rad_interaction'] = df['sun_elevation:d'] * df['direct_rad:W']\n",
    "\n",
    "    # Precipitation Features\n",
    "    df['precip'] = df['precip_5min:mm']*df['precip_type_5min:idx']\n",
    "\n",
    "    # Safeguard in case of inf values\n",
    "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_features(df):\n",
    "    \"\"\"\n",
    "    Adds 'month', 'year', 'hour' and 'day' columns to the dataframe based on the 'date_forecast' column.\n",
    "    Also adds 'hour_sin' and 'hour_cos' columns for the hour of the day.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if 'date_forecast' exists in the dataframe\n",
    "    if 'date_forecast' in df.columns:\n",
    "        # Convert the 'date_forecast' column to datetime format\n",
    "        df['date_forecast'] = pd.to_datetime(df['date_forecast'])\n",
    "        \n",
    "        # Extract month, year, hour and day\n",
    "        df['month'] = df['date_forecast'].dt.month\n",
    "        df['year'] = df['date_forecast'].dt.year\n",
    "        df['hour'] = df['date_forecast'].dt.hour\n",
    "        df['day'] = df['date_forecast'].dt.day\n",
    "        df['hour_sin'] = np.sin(2*np.pi*df['hour']/24)\n",
    "        df['hour_cos'] = np.cos(2*np.pi*df['hour']/24)\n",
    "\n",
    "    else:\n",
    "        print(\"Warning: 'date_forecast' column not found in the dataframe. No date features added.\")\n",
    "        return df  # Keep the 'date_forecast' column in the dataframe\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding discretized features for the continuous variables to help tree-based models\n",
    "\n",
    "def bin_columns(dataframe, columns_to_bin, n_bins=5):\n",
    "    \"\"\"\n",
    "    Bins the specified columns of the dataframe into equal-sized bins.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataframe: pd.DataFrame\n",
    "    - columns_to_bin: list of strings, the names of the columns to bin\n",
    "    - n_bins: int or dict, the number of bins for each column (if int, use the same number for all columns;\n",
    "              if dict, specify individual numbers with column names as keys)\n",
    "    \n",
    "    Returns:\n",
    "    - binned_dataframe: pd.DataFrame, the dataframe with the specified columns binned\n",
    "    \"\"\"\n",
    "    binned_dataframe = dataframe.copy()\n",
    "    \n",
    "    for column in columns_to_bin:\n",
    "        # Determine the number of bins for this column\n",
    "        bins = n_bins if isinstance(n_bins, int) else n_bins.get(column, 5)\n",
    "        \n",
    "        # Create quantile-based bins\n",
    "        binned_dataframe[f'binned_{column}'] = pd.qcut(\n",
    "            binned_dataframe[column],\n",
    "            q=bins,\n",
    "            labels=False,\n",
    "            duplicates='drop'\n",
    "        )\n",
    "        \n",
    "    return binned_dataframe\n",
    "\n",
    "def add_binned_features(df):\n",
    "    columns_to_bin = [\n",
    "        'super_cooled_liquid_water:kgm2',\n",
    "        'ceiling_height_agl:m',\n",
    "        'cloud_base_agl:m'\n",
    "    ]\n",
    "\n",
    "    # Bin the columns\n",
    "    # df = bin_columns(df, columns_to_bin)\n",
    "    df = bin_columns(df, ['effective_cloud_cover:p'], n_bins=2)\n",
    "    df = bin_columns(df, ['ceiling_height_agl:m'], n_bins=3)\n",
    "    df = bin_columns(df, ['average_wind_speed'], n_bins=5)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rate_of_change_features(df, features, second_order=False):\n",
    "    \"\"\"\n",
    "    Adds rate of change columns for specified features in the dataframe.\n",
    "    Assumes the dataframe is time sorted. If second_order is True, it also adds the second order rate of change.\n",
    "    \"\"\"\n",
    "    for feature in features:\n",
    "        rate_column_name = feature + '_rate_of_change'\n",
    "        df[rate_column_name] = df[feature].diff().fillna(0)  # Handle the first diff NaN if required\n",
    "        \n",
    "        if second_order:  # Check if second order difference is required\n",
    "            second_order_column_name = feature + '_rate_of_change_of_change'\n",
    "            df[second_order_column_name] = df[rate_column_name].diff().fillna(0)  # Second order difference\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_rate_of_change_features_to_df(df):\n",
    "    # Define the features for which to calculate rate of change\n",
    "    features_to_diff = [\n",
    "        't_1000hPa:K',\n",
    "        'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad:W',\n",
    "        'effective_cloud_cover:p', 'total_radiation:W'\n",
    "    ]\n",
    "\n",
    "    # Add rate of change features\n",
    "    return add_rate_of_change_features(df, features_to_diff, second_order=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_est_obs_feature(df):\n",
    "    \"\"\"\n",
    "    Adds a column to the dataframe that indicates whether the data is estimated or observed.\n",
    "    \"\"\"\n",
    "    # Add the est_obs feature\n",
    "    if 'date_calc' not in df.columns:\n",
    "        # If 'date_calc' does not exist, create 'observed' column and set to 1\n",
    "        df['observed'] = 1\n",
    "        return df\n",
    "    else:\n",
    "        # If 'date_calc' exists, create a new column and set values to 0\n",
    "        df['observed'] = 0\n",
    "        return df.drop(columns=['date_calc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_constant_regions(dataframe, column_name=\"pv_measurement\", threshold=72):\n",
    "    \"\"\"\n",
    "    Removes rows where the specified column has constant values for more than the given threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the specified column exists in the dataframe\n",
    "    if column_name not in dataframe.columns:\n",
    "        print(f\"Warning: '{column_name}' column not found in the dataframe. No rows removed.\")\n",
    "        return dataframe\n",
    "    \n",
    "    same_as_previous = dataframe[column_name].eq(dataframe[column_name].shift())\n",
    "    group_ids = (~same_as_previous).cumsum()\n",
    "    to_remove = group_ids[same_as_previous].value_counts() > threshold\n",
    "    group_ids_to_remove = to_remove[to_remove].index\n",
    "    \n",
    "    # Drop entire rows that match the conditions\n",
    "    return dataframe.drop(dataframe[group_ids.isin(group_ids_to_remove)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lagged_features(df, features_with__lags, fill_value=None):\n",
    "    \"\"\"\n",
    "    Adds lagged columns for specified features in the dataframe with specific lag periods.\n",
    "    'features_with_specific_lags' is a dictionary with features as keys and specific lag as values.\n",
    "    'fill_value' is what to fill the NaNs with, after shifting.\n",
    "    \"\"\"\n",
    "    for feature, specific_lag in features_with__lags.items():\n",
    "        lag_column_name = f\"{feature}_lag_{specific_lag}\"\n",
    "        df[lag_column_name] = df[feature].shift(specific_lag).fillna(fill_value)\n",
    "    return df\n",
    "\n",
    "def add_lagged_features_to_df(df):\n",
    "    features_with_lags = {\n",
    "        'total_radiation:W': 1,\n",
    "        'total_radiation:W': -1,\n",
    "        'rad_diff:W': 1,\n",
    "        'rad_diff:W': -1,\n",
    "        'total_radiation_1h:J': 1,\n",
    "        'total_radiation_1h:J': -1\n",
    "    }\n",
    "\n",
    "    # Add lagged features for specific lags\n",
    "    return add_lagged_features(df, features_with_lags, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function sets all nans to 0. We've explored with dropping nans completely, but filling nans with 0 provided better results. This shows that nan may often represents 0, which makes sense in columns such as `ceiling_height_agl:m` and `cloud_base_agl:m`. These had to be set to 0 in the test data before removing nans, because the test data had mostly nans in these features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_nan(df):\n",
    "    # Remove the rows where target is nan\n",
    "    try:\n",
    "        df = df[df['pv_measurement'].notna()]\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    # Set all remaining nans to 0\n",
    "    return df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'pv_measurement' column not found in the dataframe. No rows removed.\n",
      "Warning: 'pv_measurement' column not found in the dataframe. No rows removed.\n",
      "Warning: 'pv_measurement' column not found in the dataframe. No rows removed.\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(df):\n",
    "    df = add_experimental_features(df)\n",
    "    df = add_date_features(df)\n",
    "    df = add_binned_features(df)\n",
    "    df = add_rate_of_change_features_to_df(df)\n",
    "    df = add_est_obs_feature(df)\n",
    "    df = remove_constant_regions(df)\n",
    "    df = add_lagged_features_to_df(df)\n",
    "    df = handle_nan(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Preprocess\n",
    "obs_A = preprocessing(obs_A)\n",
    "est_A = preprocessing(est_A)\n",
    "test_A = preprocessing(test_A)\n",
    "\n",
    "obs_B = preprocessing(obs_B)\n",
    "est_B = preprocessing(est_B)\n",
    "test_B = preprocessing(test_B)\n",
    "\n",
    "obs_C = preprocessing(obs_C)\n",
    "est_C = preprocessing(est_C)\n",
    "test_C = preprocessing(test_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29667, 89)\n",
      "(4418, 89)\n",
      "(720, 86)\n"
     ]
    }
   ],
   "source": [
    "# Inpspect the data\n",
    "print(obs_A.shape)\n",
    "print(est_A.shape)\n",
    "print(test_A.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seeds used for reproducibility\n",
    "# 32 weights: 0.3, 0.3, 0.4\n",
    "# 24 weights: 0.3, 0.3, 0.4\n",
    "# 33 (without winter months 1 and 12) weights: 0.2, 0.4, 0.4\n",
    "# 11 (without winter months 1, 2 and 11, 12) weights: 0.25, 0.35, 0.4\n",
    "# 5 weights: 0.4, 0.3, 0.3\n",
    "\n",
    "# Best score is the mean prediction of all the 5 seeds mentioned above. The first weight is xgboost, the second is catboost, and the third is autogluon.\n",
    "\n",
    "# Set the random seed\n",
    "np.random.seed(4)\n",
    "\n",
    "# Concatinate\n",
    "A = pd.concat([obs_A, est_A])\n",
    "B = pd.concat([obs_B, est_B])\n",
    "C = pd.concat([obs_C, est_C])\n",
    "\n",
    "# Remove characters unparseable for CatBoost \n",
    "A.columns = [col.replace('[', '').replace(']', '').replace(',', '').replace('{', '').replace('}', '').replace('(', '').replace(')', '').replace('\"', '').replace(\"'\", '').replace(':', '').replace('\\\\', '') for col in A.columns]\n",
    "B.columns = [col.replace('[', '').replace(']', '').replace(',', '').replace('{', '').replace('}', '').replace('(', '').replace(')', '').replace('\"', '').replace(\"'\", '').replace(':', '').replace('\\\\', '') for col in B.columns]\n",
    "C.columns = [col.replace('[', '').replace(']', '').replace(',', '').replace('{', '').replace('}', '').replace('(', '').replace(')', '').replace('\"', '').replace(\"'\", '').replace(':', '').replace('\\\\', '') for col in C.columns]\n",
    "\n",
    "test_A.columns = [col.replace('[', '').replace(']', '').replace(',', '').replace('{', '').replace('}', '').replace('(', '').replace(')', '').replace('\"', '').replace(\"'\", '').replace(':', '').replace('\\\\', '') for col in test_A.columns]\n",
    "test_B.columns = [col.replace('[', '').replace(']', '').replace(',', '').replace('{', '').replace('}', '').replace('(', '').replace(')', '').replace('\"', '').replace(\"'\", '').replace(':', '').replace('\\\\', '') for col in test_B.columns]\n",
    "test_C.columns = [col.replace('[', '').replace(']', '').replace(',', '').replace('{', '').replace('}', '').replace('(', '').replace(')', '').replace('\"', '').replace(\"'\", '').replace(':', '').replace('\\\\', '') for col in test_C.columns]\n",
    "\n",
    "# Getting validation data from summer months, because the test set is from summer months. We experimentet with excluding winter months\n",
    "# from the training data here.\n",
    "\n",
    "# Step 1: Filter A to include only months from March to October\n",
    "A = A[A['date_forecast'].dt.month.isin([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])]\n",
    "\n",
    "# Step 2: Identify unique days within May, June, and July\n",
    "summer_months = A[A['date_forecast'].dt.month.isin([5, 6])]\n",
    "unique_summer_days = summer_months['date_forecast'].dt.date.unique()\n",
    "\n",
    "# Step 3: Sample these days for val_A\n",
    "sampled_days = np.random.choice(unique_summer_days, size=int(len(unique_summer_days) * 0.4), replace=False)\n",
    "val_A = A[A['date_forecast'].dt.date.isin(sampled_days)]\n",
    "\n",
    "# Step 4: Define train_A as the remaining data\n",
    "train_A = A[~A['date_forecast'].dt.date.isin(sampled_days)]\n",
    "\n",
    "# Prepare your features and target variables\n",
    "X_train_A = train_A.drop(columns='pv_measurement')\n",
    "y_train_A = train_A['pv_measurement']\n",
    "X_val_A = val_A.drop(columns='pv_measurement')\n",
    "y_val_A = val_A['pv_measurement']\n",
    "\n",
    "# Repeat for B and C\n",
    "B = B[B['date_forecast'].dt.month.isin([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])]\n",
    "summer_months = B[B['date_forecast'].dt.month.isin([5, 6])]\n",
    "unique_summer_days = summer_months['date_forecast'].dt.date.unique()\n",
    "sampled_days = np.random.choice(unique_summer_days, size=int(len(unique_summer_days) * 0.4), replace=False)\n",
    "val_B = B[B['date_forecast'].dt.date.isin(sampled_days)]\n",
    "train_B = B[~B['date_forecast'].dt.date.isin(sampled_days)]\n",
    "X_train_B = train_B.drop(columns='pv_measurement')\n",
    "y_train_B = train_B['pv_measurement']\n",
    "X_val_B = val_B.drop(columns='pv_measurement')\n",
    "y_val_B = val_B['pv_measurement']\n",
    "\n",
    "C = C[C['date_forecast'].dt.month.isin([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])]\n",
    "summer_months = C[C['date_forecast'].dt.month.isin([5, 6])]\n",
    "unique_summer_days = summer_months['date_forecast'].dt.date.unique()\n",
    "sampled_days = np.random.choice(unique_summer_days, size=int(len(unique_summer_days) * 0.4), replace=False)\n",
    "val_C = C[C['date_forecast'].dt.date.isin(sampled_days)]\n",
    "train_C = C[~C['date_forecast'].dt.date.isin(sampled_days)]\n",
    "X_train_C = train_C.drop(columns='pv_measurement')\n",
    "y_train_C = train_C['pv_measurement']\n",
    "X_val_C = val_C.drop(columns='pv_measurement')\n",
    "y_val_C = val_C['pv_measurement']\n",
    "\n",
    "# Drop date_forecast\n",
    "train_A = train_A.drop(columns=['date_forecast', 'date_forecast_x', 'date_forecast_y'])\n",
    "train_B = train_B.drop(columns=['date_forecast', 'date_forecast_x', 'date_forecast_y'])\n",
    "train_C = train_C.drop(columns=['date_forecast', 'date_forecast_x', 'date_forecast_y'])\n",
    "val_A = val_A.drop(columns=['date_forecast', 'date_forecast_x', 'date_forecast_y'])\n",
    "val_B = val_B.drop(columns=['date_forecast', 'date_forecast_x', 'date_forecast_y'])\n",
    "val_C = val_C.drop(columns=['date_forecast', 'date_forecast_x', 'date_forecast_y'])\n",
    "X_train_A = X_train_A.drop(columns=['date_forecast', 'date_forecast_x', 'date_forecast_y'])\n",
    "X_train_B = X_train_B.drop(columns=['date_forecast', 'date_forecast_x', 'date_forecast_y'])\n",
    "X_train_C = X_train_C.drop(columns=['date_forecast', 'date_forecast_x', 'date_forecast_y'])\n",
    "X_val_A = X_val_A.drop(columns=['date_forecast', 'date_forecast_x', 'date_forecast_y'])\n",
    "X_val_B = X_val_B.drop(columns=['date_forecast', 'date_forecast_x', 'date_forecast_y'])\n",
    "X_val_C = X_val_C.drop(columns=['date_forecast', 'date_forecast_x', 'date_forecast_y'])\n",
    "test_A = test_A.drop(columns=['date_forecast'])\n",
    "test_B = test_B.drop(columns=['date_forecast'])\n",
    "test_C = test_C.drop(columns=['date_forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 85)\n",
      "(32069, 86)\n"
     ]
    }
   ],
   "source": [
    "# Inspect test train split\n",
    "print(test_A.shape)\n",
    "print(train_A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model parameter tuning**\n",
    "\n",
    "We used gridsearch on XGBoost for obtaining these parameters with the same train-test split. Autogluon tunes itself according to the tuning data (which is our summer validation data). We used default parameters for CatBoost, and LightGBM was used a lot in the beginning, but we dropped it as it lead to worse predictions. AutoGluon has multiple presets, but all other presets than \"medium_quality\" seemed to overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lgbm_A = lgb.Dataset(X_train_A, label=y_train_A)\n",
    "val_lgbm_A = lgb.Dataset(X_val_A, label=y_val_A, reference=train_lgbm_A)\n",
    "\n",
    "train_lgbm_B = lgb.Dataset(X_train_B, label=y_train_B)\n",
    "val_lgbm_B = lgb.Dataset(X_val_B, label=y_val_B, reference=train_lgbm_B)\n",
    "\n",
    "train_lgbm_C = lgb.Dataset(X_train_C, label=y_train_C)\n",
    "val_lgbm_C = lgb.Dataset(X_val_C, label=y_val_C, reference=train_lgbm_C)\n",
    "\n",
    "train_auto_A = TabularDataset(train_A)\n",
    "val_auto_A = TabularDataset(val_A)\n",
    "\n",
    "train_auto_B = TabularDataset(train_B)\n",
    "val_auto_B = TabularDataset(val_B)\n",
    "\n",
    "train_auto_C = TabularDataset(train_C)\n",
    "val_auto_C = TabularDataset(val_C)\n",
    "\n",
    "auto_label = 'pv_measurement'\n",
    "\n",
    "# Set the parameters for the LGBM models\n",
    "params_lgbm = {\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "# Set the parameters for the XGBoost models\n",
    "params_xgb_A = {\n",
    "    'colsample_bytree': 0.8, \n",
    "    'gamma': 0.4, \n",
    "    'learning_rate': 0.012, \n",
    "    'max_depth': 15, \n",
    "    'min_child_weight': 10, \n",
    "    'n_estimators': 600, \n",
    "    'reg_alpha': 0.8, \n",
    "    'reg_lambda': 0.8, \n",
    "    'subsample': 0.912,\n",
    "    'random_state': 0, \n",
    "    'booster': 'gbtree',\n",
    "    'n_jobs': -1,\n",
    "    'num_parallel_tree': 2\n",
    "}\n",
    "\n",
    "params_xgb_B = {\n",
    "    'colsample_bytree': 0.8, \n",
    "    'gamma': 0.8, \n",
    "    'learning_rate': 0.008, \n",
    "    'max_depth': 15, \n",
    "    'min_child_weight': 10, \n",
    "    'n_estimators': 600, \n",
    "    'reg_alpha': 1, \n",
    "    'reg_lambda': 3, \n",
    "    'subsample': 0.912,\n",
    "    'random_state': 0, \n",
    "    'booster': 'gbtree',\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "params_xgb_C = {\n",
    "    'colsample_bytree': 0.8, \n",
    "    'gamma': 0.8, \n",
    "    'learning_rate': 0.008, \n",
    "    'max_depth': 15, \n",
    "    'min_child_weight': 10, \n",
    "    'n_estimators': 600, \n",
    "    'reg_alpha': 1, \n",
    "    'reg_lambda': 3, \n",
    "    'subsample': 0.912,\n",
    "    'random_state': 0, \n",
    "    'booster': 'gbtree',\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "xgb_A = xgb.XGBRegressor(**params_xgb_A)\n",
    "xgb_B = xgb.XGBRegressor(**params_xgb_B)\n",
    "xgb_C = xgb.XGBRegressor(**params_xgb_C)\n",
    "\n",
    "cat_A = CatBoostRegressor(\n",
    "    iterations=5000,         # The number of trees to build\n",
    "    #learning_rate=0.09,     # The learning rate\n",
    "    #depth=10,               # Depth of the tree\n",
    "    loss_function='MAE',     # Loss function to be optimized. RMSE is common for regression.\n",
    "    eval_metric='MAE',       # Evaluation metric for the validation set\n",
    "    #random_seed=42,         # Seed for reproducibility\n",
    "    #verbose=100             # Frequency of logging the training process\n",
    ")\n",
    "\n",
    "cat_B = CatBoostRegressor(\n",
    "    iterations=5000,\n",
    "    #learning_rate=0.09,\n",
    "    #depth=10,\n",
    "    loss_function='MAE',\n",
    "    eval_metric='MAE',\n",
    "    #random_seed=42,\n",
    "    #verbose=100\n",
    ")\n",
    "\n",
    "cat_C = CatBoostRegressor(\n",
    "    iterations=5000,\n",
    "    #learning_rate=0.09,\n",
    "    #depth=10,\n",
    "    loss_function='MAE',\n",
    "    eval_metric='MAE',\n",
    "    #random_seed=42,\n",
    "    #verbose=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 14990\n",
      "[LightGBM] [Info] Number of data points in the train set: 32069, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score 591.953782\n"
     ]
    }
   ],
   "source": [
    "# Train the LGBM models\n",
    "\n",
    "lgbm_A = lgb.train(params_lgbm,\n",
    "                train_lgbm_A,\n",
    "                num_boost_round=1000,\n",
    "                valid_sets=[val_lgbm_A],\n",
    "                early_stopping_rounds=50,\n",
    "                verbose_eval=50)\n",
    "\n",
    "lgbm_B = lgb.train(params_lgbm,\n",
    "                train_lgbm_B,\n",
    "                num_boost_round=1000,\n",
    "                valid_sets=[val_lgbm_B],\n",
    "                early_stopping_rounds=50,\n",
    "                verbose_eval=50)\n",
    "\n",
    "lgbm_C = lgb.train(params_lgbm,\n",
    "                train_lgbm_C,\n",
    "                num_boost_round=1000,\n",
    "                valid_sets=[val_lgbm_C],\n",
    "                early_stopping_rounds=50,\n",
    "                verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the XGBoost models. We got them to work the best when having fewer columns\n",
    "xgb_columns = [\n",
    "    'total_radiationW',\n",
    "    'snow_accumulation',\n",
    "    'super_cooled_liquid_waterkgm2',\n",
    "    'average_wind_speed',\n",
    "    'sun_elevationd',\n",
    "    'sun_azimuthd',\n",
    "    'clear_sky_radW',\n",
    "    'month',\n",
    "    't_1000hPaC',\n",
    "    'msl_pressurehPa_scaled',\n",
    "    'rain_waterkgm2',\n",
    "    'cloud_base_aglm',\n",
    "    'effective_cloud_coverp',\n",
    "    'dew_or_rimeidx'\n",
    "]\n",
    "print(train_A.columns)\n",
    "\n",
    "X_train_xgb_A = train_A[xgb_columns]\n",
    "y_train_xgb_A = train_A['pv_measurement']\n",
    "X_test_xgb_A = test_A[xgb_columns]\n",
    "\n",
    "X_train_xgb_B = train_B[xgb_columns]\n",
    "y_train_xgb_B = train_B['pv_measurement']\n",
    "X_test_xgb_B = test_B[xgb_columns]\n",
    "\n",
    "X_train_xgb_C = train_C[xgb_columns]\n",
    "y_train_xgb_C = train_C['pv_measurement']\n",
    "X_test_xgb_C = test_C[xgb_columns]\n",
    "\n",
    "# Train the XGBoost models\n",
    "xgb_A.fit(\n",
    "    X=X_train_xgb_A, y=y_train_xgb_A,\n",
    "    eval_metric='mae',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "xgb_B.fit(\n",
    "    X=X_train_xgb_B, y=y_train_xgb_B,\n",
    "    eval_metric='mae',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "xgb_C.fit(\n",
    "    X=X_train_xgb_C, y=y_train_xgb_C,\n",
    "    eval_metric='mae',\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CatBoost models\n",
    "cat_A.fit(\n",
    "    X_train_A, y_train_A,\n",
    "    eval_set=(X_val_A, y_val_A),\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "cat_B.fit(\n",
    "    X_train_B, y_train_B,\n",
    "    eval_set=(X_val_B, y_val_B),\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "cat_C.fit(\n",
    "    X_train_C, y_train_C,\n",
    "    eval_set=(X_val_C, y_val_C),\n",
    "    use_best_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_A = TabularPredictor(label=auto_label, eval_metric='mean_absolute_error', problem_type='regression').fit(train_auto_A, \n",
    "                                                                                   presets='medium_quality', \n",
    "                                                                                   tuning_data=val_auto_A, \n",
    "                                                                                   use_bag_holdout=True, \n",
    "                                                                                   ag_args_ensemble={'fold_fitting_strategy': 'sequential_local'})\n",
    "auto_A.plot_ensemble_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_B = TabularPredictor(label=auto_label, eval_metric='mean_absolute_error', problem_type='regression').fit(train_auto_B,\n",
    "                                                                                      presets='medium_quality',\n",
    "                                                                                      tuning_data=val_auto_B,\n",
    "                                                                                      use_bag_holdout=True,\n",
    "                                                                                      ag_args_ensemble={'fold_fitting_strategy': 'sequential_local'})\n",
    "auto_B.plot_ensemble_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_C = TabularPredictor(label=auto_label, eval_metric='mean_absolute_error', problem_type='regression').fit(train_auto_C,\n",
    "                                                                                        presets='medium_quality',\n",
    "                                                                                        tuning_data=val_auto_C,\n",
    "                                                                                        use_bag_holdout=True,\n",
    "                                                                                        ag_args_ensemble={'fold_fitting_strategy': 'sequential_local'})\n",
    "auto_C.plot_ensemble_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost is trained on the validation set as well on the submission, and is therefore\n",
    "# excluded from this ensemble because this is for model interpretation purposes only\n",
    "\n",
    "# Predictions\n",
    "y_pred_lgbm_A = lgbm_A.predict(X_val_A, num_iteration=lgbm_A.best_iteration)\n",
    "y_pred_lgbm_B = lgbm_B.predict(X_val_B, num_iteration=lgbm_B.best_iteration)\n",
    "y_pred_lgbm_C = lgbm_C.predict(X_val_C, num_iteration=lgbm_C.best_iteration)\n",
    "\n",
    "y_pred_xgb_A = xgb_A.predict(X_test_xgb_A)\n",
    "y_pred_xgb_B = xgb_B.predict(X_test_xgb_B)\n",
    "y_pred_xgb_C = xgb_C.predict(X_test_xgb_C)\n",
    "\n",
    "y_pred_cat_A = cat_A.predict(X_val_A)\n",
    "y_pred_cat_B = cat_B.predict(X_val_B)\n",
    "y_pred_cat_C = cat_C.predict(X_val_C)\n",
    "\n",
    "y_pred_auto_A = auto_A.predict(val_auto_A)\n",
    "y_pred_auto_B = auto_B.predict(val_auto_B)\n",
    "y_pred_auto_C = auto_C.predict(val_auto_C)\n",
    "\n",
    "y_pred_A = (y_pred_lgbm_A + y_pred_cat_A + y_pred_auto_A) / 3\n",
    "y_pred_B = (y_pred_lgbm_B + y_pred_cat_B + y_pred_auto_B) / 3\n",
    "y_pred_C = (y_pred_lgbm_C + y_pred_cat_C + y_pred_auto_C) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model interpretation**\n",
    "We saw that individual models seemed to generally guess too low or too high, and decided to ensemble them to get a better average guess. \\\n",
    "\\\n",
    "We tried to make the models compensate for eachothers misses by ensembling models in a way that makes the mean error get as close to 0 as possible and the mean absolute error be as low as possible to minimize variance. To to this, we tried to minimize the correlation between our models while increasing the correlation with the target, and stacking these to make the mean error close to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "mae_lgbm = (mean_absolute_error(y_val_A, y_pred_lgbm_A) + mean_absolute_error(y_val_B, y_pred_lgbm_B) + mean_absolute_error(y_val_C, y_pred_lgbm_C)) / 3\n",
    "me_lgbm = (np.mean(y_val_A - y_pred_lgbm_A) + np.mean(y_val_B - y_pred_lgbm_B) + np.mean(y_val_C - y_pred_lgbm_C)) / 3\n",
    "\n",
    "# mae_xgb = (mean_absolute_error(y_val_A, y_pred_xgb_A) + mean_absolute_error(y_val_B, y_pred_xgb_B) + mean_absolute_error(y_val_C, y_pred_xgb_C)) / 3\n",
    "# me_xgb = (np.mean(y_val_A - y_pred_xgb_A) + np.mean(y_val_B - y_pred_xgb_B) + np.mean(y_val_C - y_pred_xgb_C)) / 3\n",
    "\n",
    "mae_cat = (mean_absolute_error(y_val_A, y_pred_cat_A) + mean_absolute_error(y_val_B, y_pred_cat_B) + mean_absolute_error(y_val_C, y_pred_cat_C)) / 3\n",
    "me_cat = (np.mean(y_val_A - y_pred_cat_A) + np.mean(y_val_B - y_pred_cat_B) + np.mean(y_val_C - y_pred_cat_C)) / 3\n",
    "\n",
    "mae_auto = (mean_absolute_error(y_val_A, y_pred_auto_A) + mean_absolute_error(y_val_B, y_pred_auto_B) + mean_absolute_error(y_val_C, y_pred_auto_C)) / 3\n",
    "me_auto = (np.mean(y_val_A - y_pred_auto_A) + np.mean(y_val_B - y_pred_auto_B) + np.mean(y_val_C - y_pred_auto_C)) / 3\n",
    "\n",
    "mae_ensemble = (mean_absolute_error(y_val_A, y_pred_A) + mean_absolute_error(y_val_B, y_pred_B) + mean_absolute_error(y_val_C, y_pred_C)) / 3\n",
    "me_ensemble = (np.mean(y_val_A - y_pred_A) + np.mean(y_val_B - y_pred_B) + np.mean(y_val_C - y_pred_C)) / 3\n",
    "\n",
    "\n",
    "metric_data = {\n",
    "    'Model': ['LGBM', 'CatBoost', 'AutoGluon', 'Ensemble'],\n",
    "    'MAE': [mae_lgbm, mae_cat, mae_auto, mae_ensemble],\n",
    "    'ME': [me_lgbm, me_cat, me_auto, me_ensemble]\n",
    "}\n",
    "df = pd.DataFrame(metric_data)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# MAE Plot\n",
    "mae_barplot = sns.barplot(x='Model', y='MAE', data=df, ax=ax[0])\n",
    "ax[0].set_title('Mean Absolute Error (MAE) by Model')\n",
    "ax[0].set_ylabel('MAE')\n",
    "ax[0].set_xlabel('Model')\n",
    "\n",
    "# Annotate MAE values\n",
    "for p in mae_barplot.patches:\n",
    "    mae_barplot.annotate(format(p.get_height(), '.2f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 9), \n",
    "                   textcoords = 'offset points')\n",
    "\n",
    "# ME Plot\n",
    "me_barplot = sns.barplot(x='Model', y='ME', data=df, ax=ax[1])\n",
    "ax[1].set_title('Mean Error (ME) by Model')\n",
    "ax[1].set_ylabel('ME')\n",
    "ax[1].set_xlabel('Model')\n",
    "\n",
    "# Annotate ME values\n",
    "for p in me_barplot.patches:\n",
    "    me_barplot.annotate(format(p.get_height(), '.2f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 9), \n",
    "                   textcoords = 'offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation between models\n",
    "predictions = {\n",
    "    'LGBM': y_pred_lgbm_A,\n",
    "    'CAT': y_pred_cat_A,\n",
    "    'Auto': y_pred_auto_A,\n",
    "    'Target': y_val_A\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(predictions)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix between Models and Target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Selection**\n",
    "AutoGluon and CatBoost seemed to perform the best when they got as many features as possible, but we needed only the best features for XGBoost. Initially we added all the features we believed to be important from our EDA, and some that we thought that may could be important. Then we selected the final features through many rounds of selection using feature importance, and sequential feature selection. \\\n",
    "\\\n",
    "The sequential feature selection took too long to run to include in the notebook, but we did both forward, and backward feature selection. We tok the union of these feature selection methods and used for our final feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importances = xgb_A.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': list(X_train_xgb_A.columns), 'importance': feature_importances}).sort_values('importance', ascending = False)\n",
    "\n",
    "# Print feature importance\n",
    "for i in range(feature_importances.shape[0]):\n",
    "    print(f\"{i} {feature_importances.iloc[i, 0]}: {feature_importances.iloc[i, 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting with ensembling different models from the leaderboard. WeighetEnsemle seemed to work the best.\n",
    "auto_A.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "\n",
    "xgb_weight = 0.4\n",
    "cat_weight = 0.3\n",
    "auto_weight = 0.3\n",
    "\n",
    "output_file = 'submission.csv'\n",
    "\n",
    "print(test_A.shape)\n",
    "print(train_A.shape)\n",
    "\n",
    "pred_xgb_A = xgb_A.predict(X_test_xgb_C)\n",
    "pred_xgb_B = xgb_B.predict(X_test_xgb_C)\n",
    "pred_xgb_C = xgb_C.predict(X_test_xgb_C)\n",
    "\n",
    "pred_auto_A = auto_A.predict(test_A)\n",
    "pred_auto_B = auto_B.predict(test_B)\n",
    "pred_auto_C = auto_C.predict(test_C)\n",
    "\n",
    "pred_cat_A = cat_A.predict(test_A)\n",
    "pred_cat_B = cat_B.predict(test_B)\n",
    "pred_cat_C = cat_C.predict(test_C)\n",
    "\n",
    "# Ensemble that seemed the best after some experimentation\n",
    "pred_A = (pred_xgb_A*xgb_weight + pred_cat_A*cat_weight + pred_auto_A*auto_weight)\n",
    "pred_B = (pred_xgb_B*xgb_weight + pred_cat_B*cat_weight + pred_auto_B*auto_weight)\n",
    "pred_C = (pred_xgb_C*xgb_weight + pred_cat_C*cat_weight + pred_auto_C*auto_weight)\n",
    "\n",
    "pred_A = np.clip(pred_A, 0, None)\n",
    "pred_B = np.clip(pred_B, 0, None)\n",
    "pred_C = np.clip(pred_C, 0, None)\n",
    "\n",
    "# Concatenate predictions\n",
    "predictions = np.concatenate([pred_A, pred_B, pred_C])\n",
    "\n",
    "# Create an id array\n",
    "ids = np.arange(0, len(predictions))\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'prediction': predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Submission saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDT4173-MPC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
