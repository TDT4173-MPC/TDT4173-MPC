{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import PredictionErrorDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "obs_A = pd.read_parquet('../../preprocessing/data/obs_A.parquet')\n",
    "obs_B = pd.read_parquet('../../preprocessing/data/obs_B.parquet')\n",
    "obs_C = pd.read_parquet('../../preprocessing/data/obs_C.parquet')\n",
    "est_A = pd.read_parquet('../../preprocessing/data/est_A.parquet')\n",
    "est_B = pd.read_parquet('../../preprocessing/data/est_B.parquet')\n",
    "est_C = pd.read_parquet('../../preprocessing/data/est_C.parquet')\n",
    "test_A = pd.read_parquet('../../preprocessing/data/test_A.parquet')\n",
    "test_B = pd.read_parquet('../../preprocessing/data/test_B.parquet')\n",
    "test_C = pd.read_parquet('../../preprocessing/data/test_C.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate\n",
    "A = pd.concat([obs_A, est_A])\n",
    "B = pd.concat([obs_B, est_B])\n",
    "C = pd.concat([obs_C, est_C])\n",
    "\n",
    "# Step 1: Filter A to include only months from March to October\n",
    "A = A[A['date_forecast'].dt.month.isin([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])]\n",
    "\n",
    "# Step 2: Identify unique days within May, June, and July\n",
    "summer_months = A[A['date_forecast'].dt.month.isin([5, 6, 7])]\n",
    "unique_summer_days = summer_months['date_forecast'].dt.date.unique()\n",
    "\n",
    "# Step 3: Sample these days for val_A\n",
    "sampled_days = np.random.choice(unique_summer_days, size=int(len(unique_summer_days) * 0.2), replace=False)\n",
    "val_A = A[A['date_forecast'].dt.date.isin(sampled_days)]\n",
    "\n",
    "# Step 4: Define train_A as the remaining data\n",
    "train_A = A[~A['date_forecast'].dt.date.isin(sampled_days)]\n",
    "\n",
    "# Prepare your features and target variables\n",
    "X_train_A = train_A.drop(columns='pv_measurement')\n",
    "y_train_A = train_A['pv_measurement']\n",
    "X_val_A = val_A.drop(columns='pv_measurement')\n",
    "y_val_A = val_A['pv_measurement']\n",
    "\n",
    "# Repeat for B and C\n",
    "B = B[B['date_forecast'].dt.month.isin([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])]\n",
    "summer_months = B[B['date_forecast'].dt.month.isin([5, 6, 7])]\n",
    "unique_summer_days = summer_months['date_forecast'].dt.date.unique()\n",
    "sampled_days = np.random.choice(unique_summer_days, size=int(len(unique_summer_days) * 0.2), replace=False)\n",
    "val_B = B[B['date_forecast'].dt.date.isin(sampled_days)]\n",
    "train_B = B[~B['date_forecast'].dt.date.isin(sampled_days)]\n",
    "X_train_B = train_B.drop(columns='pv_measurement')\n",
    "y_train_B = train_B['pv_measurement']\n",
    "X_val_B = val_B.drop(columns='pv_measurement')\n",
    "y_val_B = val_B['pv_measurement']\n",
    "\n",
    "C = C[C['date_forecast'].dt.month.isin([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])]\n",
    "summer_months = C[C['date_forecast'].dt.month.isin([5, 6, 7])]\n",
    "unique_summer_days = summer_months['date_forecast'].dt.date.unique()\n",
    "sampled_days = np.random.choice(unique_summer_days, size=int(len(unique_summer_days) * 0.2), replace=False)\n",
    "val_C = C[C['date_forecast'].dt.date.isin(sampled_days)]\n",
    "train_C = C[~C['date_forecast'].dt.date.isin(sampled_days)]\n",
    "X_train_C = train_C.drop(columns='pv_measurement')\n",
    "y_train_C = train_C['pv_measurement']\n",
    "X_val_C = val_C.drop(columns='pv_measurement')\n",
    "y_val_C = val_C['pv_measurement']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A = TabularDataset(train_A)\n",
    "train_B = TabularDataset(train_B)\n",
    "train_C = TabularDataset(train_C)\n",
    "val_A = TabularDataset(val_A)\n",
    "val_B = TabularDataset(val_B)\n",
    "val_C = TabularDataset(val_C)\n",
    "test_A = TabularDataset(test_A)\n",
    "test_B = TabularDataset(test_B)\n",
    "test_C = TabularDataset(test_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'pv_measurement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231111_212041/\"\n",
      "Presets specified: ['good_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "WARNING: Attempted to disable saving of bagged fold models when `use_bag_holdout=True`. Forcing `save_bag_folds=True` to avoid errors.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231111_212041/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Wed Aug 10 14:28:23 PDT 2022; root:xnu-8020.141.5~2/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   53.26 GB / 494.38 GB (10.8%)\n",
      "Train Data Rows:    34085\n",
      "Train Data Columns: 16\n",
      "Tuning Data Rows:    1608\n",
      "Tuning Data Columns: 16\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 630.59471, 1165.90242)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5701.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.43 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :  1 | ['date_forecast']\n",
      "\t\t('float', [])    : 14 | ['total_radiation:W', 'total_radiation_1h:J', 'snow_accumulation', 'super_cooled_liquid_water:kgm2', 'average_wind_speed', ...]\n",
      "\t\t('int', [])      :  1 | ['month']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 14 | ['total_radiation:W', 'total_radiation_1h:J', 'snow_accumulation', 'super_cooled_liquid_water:kgm2', 'average_wind_speed', ...]\n",
      "\t\t('int', [])                  :  1 | ['month']\n",
      "\t\t('int', ['datetime_as_int']) :  4 | ['date_forecast', 'date_forecast.year', 'date_forecast.day', 'date_forecast.dayofweek']\n",
      "\t0.2s = Fit runtime\n",
      "\t16 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.28 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mathiasotnes/Desktop/TDT4173/Project/Analysis/Mathias/autoML/autogluon.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mathiasotnes/Desktop/TDT4173/Project/Analysis/Mathias/autoML/autogluon.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Fit the predictors\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mathiasotnes/Desktop/TDT4173/Project/Analysis/Mathias/autoML/autogluon.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predictor_A \u001b[39m=\u001b[39m TabularPredictor(label\u001b[39m=\u001b[39;49mlabel, eval_metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean_absolute_error\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(A, presets\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgood_quality\u001b[39;49m\u001b[39m'\u001b[39;49m, tuning_data\u001b[39m=\u001b[39;49mval_A, use_bag_holdout\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, ag_args_ensemble\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mfold_fitting_strategy\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39msequential_local\u001b[39;49m\u001b[39m'\u001b[39;49m})\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/utils/decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     gargs, gkwargs \u001b[39m=\u001b[39m g(\u001b[39m*\u001b[39mother_args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49mgargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/tabular/predictor/predictor.py:986\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mfit_weighted_ensemble\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave(silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    987\u001b[0m     X\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[1;32m    988\u001b[0m     X_val\u001b[39m=\u001b[39;49mtuning_data,\n\u001b[1;32m    989\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49munlabeled_data,\n\u001b[1;32m    990\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[1;32m    991\u001b[0m     num_bag_folds\u001b[39m=\u001b[39;49mnum_bag_folds,\n\u001b[1;32m    992\u001b[0m     num_bag_sets\u001b[39m=\u001b[39;49mnum_bag_sets,\n\u001b[1;32m    993\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[1;32m    994\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[1;32m    995\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[1;32m    996\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[1;32m    997\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m    998\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    999\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m   1000\u001b[0m     verbosity\u001b[39m=\u001b[39;49mverbosity,\n\u001b[1;32m   1001\u001b[0m     use_bag_holdout\u001b[39m=\u001b[39;49muse_bag_holdout,\n\u001b[1;32m   1002\u001b[0m )\n\u001b[1;32m   1003\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_post_fit_vars()\n\u001b[1;32m   1005\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_fit(\n\u001b[1;32m   1006\u001b[0m     keep_only_best\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mkeep_only_best\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1007\u001b[0m     refit_full\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mrefit_full\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[1;32m   1013\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/tabular/learner/abstract_learner.py:159\u001b[0m, in \u001b[0;36mAbstractTabularLearner.fit\u001b[0;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLearner is already fit.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_input(X\u001b[39m=\u001b[39mX, X_val\u001b[39m=\u001b[39mX_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 159\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X\u001b[39m=\u001b[39;49mX, X_val\u001b[39m=\u001b[39;49mX_val, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/tabular/learner/default_learner.py:157\u001b[0m, in \u001b[0;36mDefaultLearner._fit\u001b[0;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_metric \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39meval_metric\n\u001b[1;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[0;32m--> 157\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    158\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    159\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    160\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    161\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    162\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    163\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[1;32m    164\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit_trainer,\n\u001b[1;32m    165\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    166\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m    167\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    168\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrainer_fit_kwargs,\n\u001b[1;32m    169\u001b[0m )\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_trainer(trainer\u001b[39m=\u001b[39mtrainer)\n\u001b[1;32m    171\u001b[0m time_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/tabular/trainer/auto_trainer.py:114\u001b[0m, in \u001b[0;36mAutoTrainer.fit\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m log_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m}\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m logger\u001b[39m.\u001b[39mlog(\u001b[39m20\u001b[39m, log_str)\n\u001b[0;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_and_ensemble(\n\u001b[1;32m    115\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    116\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    117\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    118\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    119\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    120\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[1;32m    121\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[1;32m    122\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m    123\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[1;32m    124\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[1;32m    125\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    126\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m    127\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py:2371\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_and_ensemble\u001b[0;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[1;32m   2369\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_rows_val \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(X_val)\n\u001b[1;32m   2370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_cols_train \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m-> 2371\u001b[0m model_names_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_multi_levels(\n\u001b[1;32m   2372\u001b[0m     X,\n\u001b[1;32m   2373\u001b[0m     y,\n\u001b[1;32m   2374\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[1;32m   2375\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m   2376\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m   2377\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m   2378\u001b[0m     level_start\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2379\u001b[0m     level_end\u001b[39m=\u001b[39;49mnum_stack_levels \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2380\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m   2381\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2382\u001b[0m )\n\u001b[1;32m   2383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_model_names()) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2384\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAutoGluon did not successfully train any models\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py:395\u001b[0m, in \u001b[0;36mAbstractTrainer.train_multi_levels\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    393\u001b[0m         core_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_core)\n\u001b[1;32m    394\u001b[0m         aux_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_aux)\n\u001b[0;32m--> 395\u001b[0m     base_model_names, aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level(\n\u001b[1;32m    396\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    397\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    398\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    399\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    400\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    401\u001b[0m         models\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[1;32m    402\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    403\u001b[0m         base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[1;32m    404\u001b[0m         core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs_level,\n\u001b[1;32m    405\u001b[0m         aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs_level,\n\u001b[1;32m    406\u001b[0m         name_suffix\u001b[39m=\u001b[39;49mname_suffix,\n\u001b[1;32m    407\u001b[0m         infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    408\u001b[0m         infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m    409\u001b[0m     )\n\u001b[1;32m    410\u001b[0m     model_names_fit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m base_model_names \u001b[39m+\u001b[39m aux_models\n\u001b[1;32m    411\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_best \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(model_names_fit) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py:539\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    537\u001b[0m     core_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[1;32m    538\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[0;32m--> 539\u001b[0m core_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level_core(\n\u001b[1;32m    540\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    541\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    542\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    543\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    544\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    545\u001b[0m     models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m    546\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    547\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    548\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m    549\u001b[0m     base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[1;32m    550\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcore_kwargs,\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    553\u001b[0m \u001b[39mif\u001b[39;00m X_val \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m     aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_new_level_aux(\n\u001b[1;32m    555\u001b[0m         X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, base_model_names\u001b[39m=\u001b[39mcore_models, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, infer_limit\u001b[39m=\u001b[39minfer_limit, infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39maux_kwargs\n\u001b[1;32m    556\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py:673\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level_core\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m fit_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[1;32m    672\u001b[0m \u001b[39m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi(\n\u001b[1;32m    674\u001b[0m     X\u001b[39m=\u001b[39;49mX_init,\n\u001b[1;32m    675\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    676\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    677\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    678\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    679\u001b[0m     models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m    680\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    681\u001b[0m     stack_name\u001b[39m=\u001b[39;49mstack_name,\n\u001b[1;32m    682\u001b[0m     compute_score\u001b[39m=\u001b[39;49mcompute_score,\n\u001b[1;32m    683\u001b[0m     fit_kwargs\u001b[39m=\u001b[39;49mfit_kwargs,\n\u001b[1;32m    684\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    685\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py:2321\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi\u001b[0;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[39mif\u001b[39;00m n_repeat_start \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2320\u001b[0m     time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m-> 2321\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_initial(\n\u001b[1;32m   2322\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   2323\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   2324\u001b[0m         models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m   2325\u001b[0m         k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m   2326\u001b[0m         n_repeats\u001b[39m=\u001b[39;49mn_repeats_initial,\n\u001b[1;32m   2327\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs,\n\u001b[1;32m   2328\u001b[0m         feature_prune_kwargs\u001b[39m=\u001b[39;49mfeature_prune_kwargs,\n\u001b[1;32m   2329\u001b[0m         time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m   2330\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2331\u001b[0m     )\n\u001b[1;32m   2332\u001b[0m     n_repeat_start \u001b[39m=\u001b[39m n_repeats_initial\n\u001b[1;32m   2333\u001b[0m     \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py:2170\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_initial\u001b[0;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   2168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2169\u001b[0m     time_ratio \u001b[39m=\u001b[39m hpo_time_ratio \u001b[39mif\u001b[39;00m hpo_enabled \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 2170\u001b[0m     models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_fold(\n\u001b[1;32m   2171\u001b[0m         models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m   2172\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs,\n\u001b[1;32m   2173\u001b[0m         k_fold_start\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2174\u001b[0m         k_fold_end\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m   2175\u001b[0m         n_repeats\u001b[39m=\u001b[39;49mn_repeats,\n\u001b[1;32m   2176\u001b[0m         n_repeat_start\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2177\u001b[0m         time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m   2178\u001b[0m         time_split\u001b[39m=\u001b[39;49mtime_split,\n\u001b[1;32m   2179\u001b[0m         time_ratio\u001b[39m=\u001b[39;49mtime_ratio,\n\u001b[1;32m   2180\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args,\n\u001b[1;32m   2181\u001b[0m     )\n\u001b[1;32m   2183\u001b[0m multi_fold_time_elapsed \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m multi_fold_time_start\n\u001b[1;32m   2184\u001b[0m \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py:2278\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_fold\u001b[0;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   2276\u001b[0m         time_start_model \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   2277\u001b[0m         time_left \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time_start_model \u001b[39m-\u001b[39m time_start)\n\u001b[0;32m-> 2278\u001b[0m model_name_trained_lst \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_single_full(\n\u001b[1;32m   2279\u001b[0m     X, y, model, time_limit\u001b[39m=\u001b[39;49mtime_left, hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs_model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m   2280\u001b[0m )\n\u001b[1;32m   2282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m   2283\u001b[0m     \u001b[39mdel\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py:2051\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single_full\u001b[0;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[1;32m   2047\u001b[0m         bagged_model_fit_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bagged_model_fit_kwargs(\n\u001b[1;32m   2048\u001b[0m             k_fold\u001b[39m=\u001b[39mk_fold, k_fold_start\u001b[39m=\u001b[39mk_fold_start, k_fold_end\u001b[39m=\u001b[39mk_fold_end, n_repeats\u001b[39m=\u001b[39mn_repeats, n_repeat_start\u001b[39m=\u001b[39mn_repeat_start\n\u001b[1;32m   2049\u001b[0m         )\n\u001b[1;32m   2050\u001b[0m         model_fit_kwargs\u001b[39m.\u001b[39mupdate(bagged_model_fit_kwargs)\n\u001b[0;32m-> 2051\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_and_save(\n\u001b[1;32m   2052\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   2053\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   2054\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   2055\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m   2056\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m   2057\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m   2058\u001b[0m         stack_name\u001b[39m=\u001b[39;49mstack_name,\n\u001b[1;32m   2059\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   2060\u001b[0m         compute_score\u001b[39m=\u001b[39;49mcompute_score,\n\u001b[1;32m   2061\u001b[0m         total_resources\u001b[39m=\u001b[39;49mtotal_resources,\n\u001b[1;32m   2062\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs,\n\u001b[1;32m   2063\u001b[0m     )\n\u001b[1;32m   2064\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[1;32m   2065\u001b[0m \u001b[39mreturn\u001b[39;00m model_names_trained\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py:1733\u001b[0m, in \u001b[0;36mAbstractTrainer._train_and_save\u001b[0;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1731\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single(X_w_pseudo, y_w_pseudo, model, X_val, y_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[1;32m   1732\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1733\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_single(X, y, model, X_val, y_val, total_resources\u001b[39m=\u001b[39;49mtotal_resources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs)\n\u001b[1;32m   1735\u001b[0m fit_end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_evaluation:\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py:1684\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single\u001b[0;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train_single\u001b[39m(\u001b[39mself\u001b[39m, X, y, model: AbstractModel, X_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, total_resources\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AbstractModel:\n\u001b[1;32m   1680\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m \u001b[39m    Trains model but does not add the trained model to this Trainer.\u001b[39;00m\n\u001b[1;32m   1682\u001b[0m \u001b[39m    Returns trained model object.\u001b[39;00m\n\u001b[1;32m   1683\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1684\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, X_val\u001b[39m=\u001b[39;49mX_val, y_val\u001b[39m=\u001b[39;49my_val, total_resources\u001b[39m=\u001b[39;49mtotal_resources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs)\n\u001b[1;32m   1685\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py:829\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_fit_resources(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    828\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_memory_usage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 829\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    831\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py:169\u001b[0m, in \u001b[0;36mStackerEnsembleModel._fit\u001b[0;34m(self, X, y, compute_base_preds, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     time_limit \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\n\u001b[0;32m--> 169\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, time_limit\u001b[39m=\u001b[39;49mtime_limit, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py:266\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit\u001b[0;34m(self, X, y, X_val, y_val, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, groups, _skip_oof, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[39m# Reserve time for final refit model\u001b[39;00m\n\u001b[1;32m    265\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m*\u001b[39m folds_to_fit \u001b[39m/\u001b[39m (folds_to_fit \u001b[39m+\u001b[39m \u001b[39m1.2\u001b[39m)\n\u001b[0;32m--> 266\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_folds(\n\u001b[1;32m    267\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    268\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    269\u001b[0m     model_base\u001b[39m=\u001b[39;49mmodel_base,\n\u001b[1;32m    270\u001b[0m     X_pseudo\u001b[39m=\u001b[39;49mX_pseudo,\n\u001b[1;32m    271\u001b[0m     y_pseudo\u001b[39m=\u001b[39;49my_pseudo,\n\u001b[1;32m    272\u001b[0m     k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m    273\u001b[0m     k_fold_start\u001b[39m=\u001b[39;49mk_fold_start,\n\u001b[1;32m    274\u001b[0m     k_fold_end\u001b[39m=\u001b[39;49mk_fold_end,\n\u001b[1;32m    275\u001b[0m     n_repeats\u001b[39m=\u001b[39;49mn_repeats,\n\u001b[1;32m    276\u001b[0m     n_repeat_start\u001b[39m=\u001b[39;49mn_repeat_start,\n\u001b[1;32m    277\u001b[0m     save_folds\u001b[39m=\u001b[39;49msave_bag_folds,\n\u001b[1;32m    278\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    279\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    280\u001b[0m )\n\u001b[1;32m    281\u001b[0m \u001b[39m# FIXME: Cleanup self\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[39m# FIXME: Support `can_refit_full=False` models\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m refit_folds:\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py:592\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit_folds\u001b[0;34m(self, X, y, model_base, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, time_limit, sample_weight, save_folds, groups, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[39mfor\u001b[39;00m fold_fit_args \u001b[39min\u001b[39;00m fold_fit_args_list:\n\u001b[1;32m    591\u001b[0m     fold_fitting_strategy\u001b[39m.\u001b[39mschedule_fold_model_fit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfold_fit_args)\n\u001b[0;32m--> 592\u001b[0m fold_fitting_strategy\u001b[39m.\u001b[39;49mafter_all_folds_scheduled()\n\u001b[1;32m    594\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m    595\u001b[0m     \u001b[39m# No need to add child times or save child here as this already occurred in the fold_fitting_strategy\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_child(model\u001b[39m=\u001b[39mmodel, add_child_times\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py:309\u001b[0m, in \u001b[0;36mSequentialLocalFoldFittingStrategy.after_all_folds_scheduled\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mafter_all_folds_scheduled\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    308\u001b[0m     \u001b[39mfor\u001b[39;00m job \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjobs:\n\u001b[0;32m--> 309\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_fold_model(job)\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py:314\u001b[0m, in \u001b[0;36mSequentialLocalFoldFittingStrategy._fit_fold_model\u001b[0;34m(self, fold_ctx)\u001b[0m\n\u001b[1;32m    312\u001b[0m time_start_fold \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    313\u001b[0m time_limit_fold \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_fold_time_limit(fold_ctx)\n\u001b[0;32m--> 314\u001b[0m fold_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_base, time_start_fold, time_limit_fold, fold_ctx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_base_kwargs)\n\u001b[1;32m    315\u001b[0m fold_model, pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict_oof(fold_model, fold_ctx)\n\u001b[1;32m    316\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_bagged_ensemble(fold_model, pred_proba, fold_ctx)\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py:349\u001b[0m, in \u001b[0;36mSequentialLocalFoldFittingStrategy._fit\u001b[0;34m(self, model_base, time_start_fold, time_limit_fold, fold_ctx, kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m     num_cpus \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_cpus, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_resources_per_job\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnum_cpus\u001b[39m\u001b[39m\"\u001b[39m, math\u001b[39m.\u001b[39minf))\n\u001b[1;32m    348\u001b[0m     num_gpus \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_gpus, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_resources_per_job\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnum_gpus\u001b[39m\u001b[39m\"\u001b[39m, math\u001b[39m.\u001b[39minf))\n\u001b[0;32m--> 349\u001b[0m fold_model\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX_fold, y\u001b[39m=\u001b[39;49my_fold, X_val\u001b[39m=\u001b[39;49mX_val_fold, y_val\u001b[39m=\u001b[39;49my_val_fold, time_limit\u001b[39m=\u001b[39;49mtime_limit_fold, num_cpus\u001b[39m=\u001b[39;49mnum_cpus, num_gpus\u001b[39m=\u001b[39;49mnum_gpus, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_fold)\n\u001b[1;32m    350\u001b[0m fold_model\u001b[39m.\u001b[39mfit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m time_start_fold\n\u001b[1;32m    351\u001b[0m \u001b[39mreturn\u001b[39;00m fold_model\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py:829\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_fit_resources(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    828\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_memory_usage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 829\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    831\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/tabular/models/lgb/lgb_model.py:194\u001b[0m, in \u001b[0;36mLGBModel._fit\u001b[0;34m(self, X, y, X_val, y_val, time_limit, num_gpus, num_cpus, sample_weight, sample_weight_val, verbosity, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_column in param dict is overridden.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m train_lgb_model(early_stopping_callback_kwargs\u001b[39m=\u001b[39;49mearly_stopping_callback_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrain_params)\n\u001b[1;32m    195\u001b[0m \u001b[39mexcept\u001b[39;00m LightGBMError:\n\u001b[1;32m    196\u001b[0m     \u001b[39mif\u001b[39;00m train_params[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/autogluon/tabular/models/lgb/lgb_utils.py:124\u001b[0m, in \u001b[0;36mtrain_lgb_model\u001b[0;34m(early_stopping_callback_kwargs, **train_params)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m booster\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_params)\n\u001b[1;32m    123\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m lgb\u001b[39m.\u001b[39;49mtrain(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrain_params)\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/lightgbm/engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[1;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[1;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[1;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[1;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[1;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/autogluon/lib/python3.8/site-packages/lightgbm/basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[1;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the predictors\n",
    "predictor_A = TabularPredictor(label=label, eval_metric='mean_absolute_error').fit(A, presets='good_quality', tuning_data=val_A, use_bag_holdout=True, ag_args_ensemble={'fold_fitting_strategy': 'sequential_local'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_B = TabularPredictor(label=label, eval_metric='mean_absolute_error').fit(B, presets='medium_quality', tuning_data=val_B, use_bag_holdout=True, ag_args_ensemble={'fold_fitting_strategy': 'sequential_local'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_C = TabularPredictor(label=label, eval_metric='mean_absolute_error').fit(C, presets='medium_quality', tuning_data=val_C, use_bag_holdout=True, ag_args_ensemble={'fold_fitting_strategy': 'sequential_local'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor_A.evaluate(test_A, silent=True)\n",
    "# predictor_B.evaluate(B, silent=True)\n",
    "# predictor_C.evaluate(C, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor_A.leaderboard(test_A, silent=False)\n",
    "# predictor_B.leaderboard(B, silent=True)\n",
    "# predictor_C.leaderboard(C, silent=True)\n",
    "\n",
    "predictor_A.plot_ensemble_model()\n",
    "predictor_B.plot_ensemble_model()\n",
    "predictor_C.plot_ensemble_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading best predictors\n",
    "# predictor_A = TabularPredictor.load(\"AutogluonModels/ag-20231106_113214/\")\n",
    "# predictor_B = TabularPredictor.load(\"AutogluonModels/ag-20231106_114820/\")\n",
    "# predictor_C = TabularPredictor.load(\"AutogluonModels/ag-20231106_120433/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_A = TabularDataset(test_A)\n",
    "# test_B = TabularDataset(test_B)\n",
    "# test_C = TabularDataset(test_C)\n",
    "\n",
    "# test_A.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "\n",
    "output_file = 'autogluon_submission_nice_mais.csv'\n",
    "\n",
    "pred_A = predictor_A.predict(test_A)\n",
    "pred_B = predictor_B.predict(test_B)\n",
    "pred_C = predictor_C.predict(test_C)\n",
    "\n",
    "pred_A = np.clip(pred_A, 0, None)\n",
    "pred_B = np.clip(pred_B, 0, None)\n",
    "pred_C = np.clip(pred_C, 0, None)\n",
    "\n",
    "# Concatenate predictions\n",
    "predictions = np.concatenate([pred_A, pred_B, pred_C])\n",
    "\n",
    "# Create an id array\n",
    "ids = np.arange(0, len(predictions))\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'prediction': predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Submission saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing\n",
    "pred_A = predictor_A.predict(val_A.drop(columns='pv_measurement'))\n",
    "pred_B = predictor_B.predict(val_B.drop(columns='pv_measurement'))\n",
    "pred_C = predictor_C.predict(val_C.drop(columns='pv_measurement'))\n",
    "\n",
    "# Evaluate \n",
    "mae_A = mean_absolute_error(val_A['pv_measurement'], pred_A)\n",
    "mae_B = mean_absolute_error(val_B['pv_measurement'], pred_B)\n",
    "mae_C = mean_absolute_error(val_C['pv_measurement'], pred_C)\n",
    "\n",
    "mae = mean_absolute_error(np.concatenate([val_A['pv_measurement'], val_B['pv_measurement'], val_C['pv_measurement']]), np.concatenate([pred_A, pred_B, pred_C]))\n",
    "\n",
    "\n",
    "print(f\"MAE A: {mae_A}\")\n",
    "print(f\"MAE B: {mae_B}\")\n",
    "print(f\"MAE C: {mae_C}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "\n",
    "# Best score features\n",
    "# MAE A: 329.7136452557737\n",
    "# MAE B: 67.42051219372165\n",
    "# MAE C: 46.51223822089323\n",
    "# MAE: 180.95353998757088\n",
    "\n",
    "# All features\n",
    "# MAE A: 290.2708872310664\n",
    "# MAE B: 65.34583249980328\n",
    "# MAE C: 42.413845591266046\n",
    "# MAE: 175.11389348063562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_A = predictor_A.predict(val_A.drop(columns='pv_measurement'))\n",
    "y_A = val_A['pv_measurement']\n",
    "fig, ax = plt.subplots()\n",
    "PredictionErrorDisplay.from_predictions(y_A, pred_A, ax=ax)\n",
    "ax.plot([y_A.min(), y_A.max()], [y_A.min(), y_A.max()], '--r', linewidth=2)\n",
    "ax.set_title('Prediction Error Plot')\n",
    "ax.set_xlabel('True Values')\n",
    "ax.set_ylabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume your peak is around observation number 0 to 1000\n",
    "start_observation = 0\n",
    "end_observation = 500\n",
    "\n",
    "# Slice the DataFrame to include only the range of interest\n",
    "peak_data = val_A[start_observation:end_observation]\n",
    "\n",
    "# Slice the predictions in the same way if they're in a separate DataFrame\n",
    "peak_predictions = predictor_A.predict(val_A.drop(columns='pv_measurement'))[start_observation:end_observation]\n",
    "\n",
    "# Now plot only that slice\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(peak_data['pv_measurement'], label='True Values', linewidth=0.5)\n",
    "plt.plot(peak_predictions, label='Predictions', linewidth=0.5)\n",
    "plt.xlabel('Observation Number')\n",
    "plt.ylabel('Target Value')\n",
    "plt.title('True Values vs Predictions for Peak')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDT4173-MPC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
