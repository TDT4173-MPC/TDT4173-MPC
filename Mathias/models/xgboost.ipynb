{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "obs_A = pd.read_parquet('../../preprocessing/data/obs_A.parquet')\n",
    "obs_B = pd.read_parquet('../../preprocessing/data/obs_B.parquet')\n",
    "obs_C = pd.read_parquet('../../preprocessing/data/obs_C.parquet')\n",
    "est_A = pd.read_parquet('../../preprocessing/data/est_A.parquet')\n",
    "est_B = pd.read_parquet('../../preprocessing/data/est_B.parquet')\n",
    "est_C = pd.read_parquet('../../preprocessing/data/est_C.parquet')\n",
    "test_A = pd.read_parquet('../../preprocessing/data/test_A.parquet')\n",
    "test_B = pd.read_parquet('../../preprocessing/data/test_B.parquet')\n",
    "test_C = pd.read_parquet('../../preprocessing/data/test_C.parquet')\n",
    "\n",
    "# Columns to drop\n",
    "columns = [\n",
    "    'date_forecast',\n",
    "    'super_cooled_liquid_water:kgm2',\n",
    "    'air_density_2m:kgm3',\n",
    "    'snow_water:kgm2',\n",
    "    'precip_5min:mm',\n",
    "    'precip_type_5min:idx',\n",
    "    'rain_water:kgm2',\n",
    "    'snow_melt_10min:mm',\n",
    "    'dew_or_rime:idx',\n",
    "    'snow_depth:cm'\n",
    "]\n",
    "\n",
    "# Drop columns\n",
    "obs_A = obs_A.drop(columns=columns)\n",
    "obs_B = obs_B.drop(columns=columns)\n",
    "obs_C = obs_C.drop(columns=columns)\n",
    "est_A = est_A.drop(columns=columns)\n",
    "est_B = est_B.drop(columns=columns)\n",
    "est_C = est_C.drop(columns=columns)\n",
    "test_A = test_A.drop(columns=columns)\n",
    "test_B = test_B.drop(columns=columns)\n",
    "test_C = test_C.drop(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate\n",
    "A = pd.concat([obs_A, est_A])\n",
    "B = pd.concat([obs_B, est_B])\n",
    "C = pd.concat([obs_C, est_C])\n",
    "\n",
    "# Data splits for submissions\n",
    "# X_A = A.drop(columns='pv_measurement')\n",
    "# y_A = A['pv_measurement']\n",
    "# X_B = B.drop(columns='pv_measurement')\n",
    "# y_B = B['pv_measurement']\n",
    "# X_C = C.drop(columns='pv_measurement')\n",
    "# y_C = C['pv_measurement']\n",
    "\n",
    "# Data splits for testing\n",
    "train_A, test_A = train_test_split(A, test_size=0.2, shuffle=True, random_state=42)\n",
    "X_train_A = train_A.drop(columns='pv_measurement')\n",
    "y_train_A = train_A['pv_measurement']\n",
    "X_test_A = test_A.drop(columns='pv_measurement')\n",
    "y_test_A = test_A['pv_measurement']\n",
    "\n",
    "train_B, test_B = train_test_split(B, test_size=0.2, shuffle=True, random_state=42)\n",
    "X_train_B = train_B.drop(columns='pv_measurement')\n",
    "y_train_B = train_B['pv_measurement']\n",
    "X_test_B = test_B.drop(columns='pv_measurement')\n",
    "y_test_B = test_B['pv_measurement']\n",
    "\n",
    "train_C, test_C = train_test_split(C, test_size=0.2, shuffle=True, random_state=42)\n",
    "X_train_C = train_C.drop(columns='pv_measurement')\n",
    "y_train_C = train_C['pv_measurement']\n",
    "X_test_C = test_C.drop(columns='pv_measurement')\n",
    "y_test_C = test_C['pv_measurement']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['clear_sky_rad:W', 'clear_sky_energy_1h:J', 'diffuse_rad:W',\n",
      "       'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J',\n",
      "       'effective_cloud_cover:p', 'sun_elevation:d',\n",
      "       'absolute_humidity_2m:gm3', 't_1000hPa:K', 'total_cloud_cover:p',\n",
      "       'visibility:m', 'msl_pressure:hPa', 'dew_point_2m:K',\n",
      "       'relative_humidity_1000hPa:p', 'pressure_gradient',\n",
      "       'temp_dewpoint_diff', 'total_radiation', 'is_day:idx',\n",
      "       'is_in_shadow:idx', 'pressure_100m:hPa', 'pressure_50m:hPa',\n",
      "       'sfc_pressure:hPa', 'prob_rime:p', 'date_forecast_fft_phase',\n",
      "       't_1000hPa:K_rate_of_change', 'clear_sky_rad:W_rate_of_change',\n",
      "       'clear_sky_rad:W_rate_of_change_of_change',\n",
      "       'diffuse_rad:W_rate_of_change',\n",
      "       'diffuse_rad:W_rate_of_change_of_change', 'direct_rad:W_rate_of_change',\n",
      "       'direct_rad:W_rate_of_change_of_change',\n",
      "       'total_radiation_rate_of_change',\n",
      "       'total_radiation_rate_of_change_of_change', 'observed',\n",
      "       'sun_azimuth:d_lag_7', 'msl_pressure:hPa_lag_3',\n",
      "       'sfc_pressure:hPa_lag_8', 't_1000hPa:K_lag_4', 'dew_or_rime:idx_lag_11',\n",
      "       'relative_humidity_1000hPa:p_lag_-3', 'wind_vector_magnitude_lag_8',\n",
      "       'temp_dewpoint_diff_lag_-4', 'dew_point_2m:K_lag_19',\n",
      "       'visibility:m_lag_-2'],\n",
      "      dtype='object')\n",
      "(81101, 45)\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "# sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "# X_reduced = sel.fit_transform(X)\n",
    "# print('Columns with low variance:')\n",
    "# for cols in X.columns:\n",
    "#     if cols not in X.columns[sel.get_support(indices=True)]:\n",
    "#         print(cols)\n",
    "\n",
    "\n",
    "# Select the k best features based on F-value for regression\n",
    "k = 45  # You can choose k based on your requirements\n",
    "selector = SelectKBest(f_regression, k=k)\n",
    "\n",
    "# Fit the selector to your data\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[selected_indices]\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Create a new DataFrame with only the selected features\n",
    "X_selected = X[selected_features]\n",
    "print(X_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mathiasotnes/Desktop/TDT4173/Project/Analysis/Mathias/models/xgboost.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mathiasotnes/Desktop/TDT4173/Project/Analysis/Mathias/models/xgboost.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m sfs \u001b[39m=\u001b[39m SequentialFeatureSelector(model, n_features_to_select\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39mtscv, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_absolute_error\u001b[39m\u001b[39m'\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mathiasotnes/Desktop/TDT4173/Project/Analysis/Mathias/models/xgboost.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Fit SFS\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mathiasotnes/Desktop/TDT4173/Project/Analysis/Mathias/models/xgboost.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m X_transformed \u001b[39m=\u001b[39m sfs\u001b[39m.\u001b[39;49mfit_transform(X_selected, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mathiasotnes/Desktop/TDT4173/Project/Analysis/Mathias/models/xgboost.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Get the selected feature indices\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mathiasotnes/Desktop/TDT4173/Project/Analysis/Mathias/models/xgboost.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m selected_features \u001b[39m=\u001b[39m sfs\u001b[39m.\u001b[39mget_support(indices\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/sklearn/base.py:881\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/sklearn/feature_selection/_sequential.py:276\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    274\u001b[0m is_auto_select \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_to_select \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_iterations):\n\u001b[0;32m--> 276\u001b[0m     new_feature_idx, new_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_best_new_feature_score(\n\u001b[1;32m    277\u001b[0m         cloned_estimator, X, y, current_mask\n\u001b[1;32m    278\u001b[0m     )\n\u001b[1;32m    279\u001b[0m     \u001b[39mif\u001b[39;00m is_auto_select \u001b[39mand\u001b[39;00m ((new_score \u001b[39m-\u001b[39m old_score) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol):\n\u001b[1;32m    280\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/sklearn/feature_selection/_sequential.py:307\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[0;34m(self, estimator, X, y, current_mask)\u001b[0m\n\u001b[1;32m    305\u001b[0m         candidate_mask \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mcandidate_mask\n\u001b[1;32m    306\u001b[0m     X_new \u001b[39m=\u001b[39m X[:, candidate_mask]\n\u001b[0;32m--> 307\u001b[0m     scores[feature_idx] \u001b[39m=\u001b[39m cross_val_score(\n\u001b[1;32m    308\u001b[0m         estimator,\n\u001b[1;32m    309\u001b[0m         X_new,\n\u001b[1;32m    310\u001b[0m         y,\n\u001b[1;32m    311\u001b[0m         cv\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv,\n\u001b[1;32m    312\u001b[0m         scoring\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscoring,\n\u001b[1;32m    313\u001b[0m         n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    314\u001b[0m     )\u001b[39m.\u001b[39mmean()\n\u001b[1;32m    315\u001b[0m new_feature_idx \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(scores, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[1;32m    316\u001b[0m \u001b[39mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173-MPC/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173-MPC/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Set up cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Set up SFS\n",
    "sfs = SequentialFeatureSelector(model, n_features_to_select='auto', cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "# Fit SFS\n",
    "X_transformed = sfs.fit_transform(X_selected, y)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_features = sfs.get_support(indices=True)\n",
    "\n",
    "print('Selected features:')\n",
    "for features in selected_features:\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize the models\n",
    "parameters = {'colsample_bytree': 0.664, \n",
    "              'gamma': 3, \n",
    "              'learning_rate': 0.012, \n",
    "              'max_depth': 12, \n",
    "              'min_child_weight': 15, \n",
    "              'n_estimators': 500, \n",
    "              'reg_alpha': 2, \n",
    "              'reg_lambda': 2, \n",
    "              'subsample': 0.912}\n",
    "\n",
    "model_A = xgb.XGBRegressor(**parameters)\n",
    "model_B = xgb.XGBRegressor(**parameters)\n",
    "model_C = xgb.XGBRegressor(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.664, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=3, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.012, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
       "             min_child_weight=15, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.664, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=3, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.012, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
       "             min_child_weight=15, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.664, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=3, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.012, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
       "             min_child_weight=15, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train prediction model\n",
    "model_A.fit(X_A, y_A)\n",
    "model_B.fit(X_B, y_B)\n",
    "model_C.fit(X_C, y_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE A: 71.29554349659497\n",
      "MAE B: 8.66896795779669\n",
      "MAE C: 8.08803972364211\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "print('MAE A:', mean_absolute_error(y_A, model_A.predict(X_A)))\n",
    "print('MAE B:', mean_absolute_error(y_B, model_B.predict(X_B)))\n",
    "print('MAE C:', mean_absolute_error(y_C, model_C.predict(X_C)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 total_radiation: 0.37481001019477844\n",
      "1 direct_rad:W: 0.23175698518753052\n",
      "2 direct_rad_1h:J: 0.11530543863773346\n",
      "3 diffuse_rad:W: 0.02941821701824665\n",
      "4 clear_sky_rad:W: 0.01888495683670044\n",
      "5 hour: 0.016049012541770935\n",
      "6 sun_azimuth:d_lag_7: 0.0109621686860919\n",
      "7 sun_elevation:d: 0.010946950875222683\n",
      "8 snow_accumulation: 0.009801385924220085\n",
      "9 total_radiation_rolling_avg_3: 0.007572078611701727\n",
      "10 effective_cloud_cover:p: 0.006856752093881369\n",
      "11 relative_humidity_1000hPa:p_lag_-3: 0.005361482966691256\n",
      "12 sun_azimuth:d: 0.00532489363104105\n",
      "13 date_forecast_fft_amplitude: 0.004698095843195915\n",
      "14 clear_sky_energy_1h:J: 0.004331118427217007\n",
      "15 temp_dewpoint_diff_lag_-4: 0.0042458176612854\n",
      "16 diffuse_rad_1h:J: 0.004193869419395924\n",
      "17 clear_sky_rad:W_rate_of_change: 0.004029703326523304\n",
      "18 t_1000hPa:K_rolling_avg_24: 0.003981053363531828\n",
      "19 total_cloud_cover:p: 0.0038206882309168577\n",
      "20 msl_pressure:hPa_lag_3: 0.003781562903895974\n",
      "21 sfc_pressure:hPa: 0.003657728433609009\n",
      "22 t_1000hPa:K_lag_4: 0.0036266387905925512\n",
      "23 visibility:m_lag_-2: 0.0035914629697799683\n",
      "24 month: 0.003488645190373063\n",
      "25 average_wind_speed: 0.003486962988972664\n",
      "26 total_cloud_cover:p_rolling_avg_6: 0.0033857598900794983\n",
      "27 dew_point_2m:K: 0.0033318018540740013\n",
      "28 pressure_50m:hPa: 0.003307206556200981\n",
      "29 msl_pressure:hPa_rolling_avg_24: 0.003284895559772849\n",
      "30 sun_elevation:d_fft_phase: 0.003257847623899579\n",
      "31 pressure_100m:hPa: 0.0030890065245330334\n",
      "32 pressure_gradient: 0.0030206155497580767\n",
      "33 wind_vector_magnitude: 0.002978366333991289\n",
      "34 absolute_humidity_2m:gm3_rolling_avg_24: 0.0029269240330904722\n",
      "35 sun_elevation:d_fft_amplitude: 0.002923424355685711\n",
      "36 t_1000hPa:K: 0.002905589062720537\n",
      "37 sfc_pressure:hPa_lag_8: 0.0028983736410737038\n",
      "38 date_forecast_fft_phase: 0.0028496442828327417\n",
      "39 dew_point_2m:K_lag_19: 0.002835556399077177\n",
      "40 observed: 0.002826491603627801\n",
      "41 msl_pressure:hPa: 0.002807879587635398\n",
      "42 direct_rad:W_rate_of_change: 0.0028020041063427925\n",
      "43 effective_cloud_cover:p_rolling_avg_6: 0.0027202810160815716\n",
      "44 clear_sky_rad:W_rate_of_change_of_change: 0.0026492970064282417\n",
      "45 total_radiation_rate_of_change: 0.0026073346380144358\n",
      "46 absolute_humidity_2m:gm3: 0.0025813241954892874\n",
      "47 year: 0.0025811297819018364\n",
      "48 clear_sky_rad:W_rolling_avg_6: 0.0025759453419595957\n",
      "49 wind_vector_magnitude_lag_8: 0.0025596171617507935\n",
      "50 effective_cloud_cover:p_rate_of_change: 0.002476664260029793\n",
      "51 t_1000hPa:K_rate_of_change: 0.002471701940521598\n",
      "52 dew_or_rime:idx_lag_11: 0.002292271936312318\n",
      "53 total_cloud_cover:p_rate_of_change: 0.002252060454338789\n",
      "54 visibility:m: 0.0022404822520911694\n",
      "55 temp_dewpoint_diff: 0.002227121265605092\n",
      "56 diffuse_rad:W_rate_of_change: 0.002192798536270857\n",
      "57 total_radiation_rate_of_change_of_change: 0.0020950206089764833\n",
      "58 sun_elevation:d_rolling_avg_6: 0.0020838493946939707\n",
      "59 direct_rad:W_rate_of_change_of_change: 0.0020375640597194433\n",
      "60 dew_point_2m:K_rate_of_change: 0.0020188933704048395\n",
      "61 relative_humidity_1000hPa:p: 0.0020099261309951544\n",
      "62 effective_cloud_cover:p_rate_of_change_of_change: 0.001984307076781988\n",
      "63 total_cloud_cover:p_rate_of_change_of_change: 0.0019493121653795242\n",
      "64 dew_point_2m:K_rate_of_change_of_change: 0.0018757217330858111\n",
      "65 diffuse_rad:W_rate_of_change_of_change: 0.0018464542226865888\n",
      "66 t_1000hPa:K_rate_of_change_of_change: 0.0017624131869524717\n",
      "67 is_day:idx: 0.0003615712921600789\n",
      "68 is_in_shadow:idx: 0.0001318226713920012\n",
      "69 prob_rime:p: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "feature_importances = model_A.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': list(X_A.columns), 'importance': feature_importances}).sort_values('importance', ascending = False)\n",
    "\n",
    "# Print feature importance\n",
    "for i in range(feature_importances.shape[0]):\n",
    "    print(f\"{i} {feature_importances.iloc[i, 0]}: {feature_importances.iloc[i, 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "\n",
    "output_file = 'submission.csv'\n",
    "\n",
    "pred_A = model_A.predict(test_A)\n",
    "pred_B = model_B.predict(test_B)\n",
    "pred_C = model_C.predict(test_C)\n",
    "\n",
    "pred_A = np.clip(pred_A, 0, None)\n",
    "pred_B = np.clip(pred_B, 0, None)\n",
    "pred_C = np.clip(pred_C, 0, None)\n",
    "\n",
    "# Concatenate predictions\n",
    "predictions = np.concatenate([pred_A, pred_B, pred_C])\n",
    "\n",
    "# Create an id array\n",
    "ids = np.arange(0, len(predictions))\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'prediction': predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Submission saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDT4173-MPC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
