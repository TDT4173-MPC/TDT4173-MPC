{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "obs_A = pd.read_parquet('../../preprocessing/data/obs_A.parquet')\n",
    "obs_B = pd.read_parquet('../../preprocessing/data/obs_B.parquet')\n",
    "obs_C = pd.read_parquet('../../preprocessing/data/obs_C.parquet')\n",
    "est_A = pd.read_parquet('../../preprocessing/data/est_A.parquet')\n",
    "est_B = pd.read_parquet('../../preprocessing/data/est_B.parquet')\n",
    "est_C = pd.read_parquet('../../preprocessing/data/est_C.parquet')\n",
    "test_A = pd.read_parquet('../../preprocessing/data/test_A.parquet')\n",
    "test_B = pd.read_parquet('../../preprocessing/data/test_B.parquet')\n",
    "test_C = pd.read_parquet('../../preprocessing/data/test_C.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate\n",
    "A = pd.concat([obs_A, est_A])\n",
    "B = pd.concat([obs_B, est_B])\n",
    "C = pd.concat([obs_C, est_C])\n",
    "\n",
    "# Data splits for submissions\n",
    "X_A = A.drop(columns='pv_measurement')\n",
    "y_A = A['pv_measurement']\n",
    "X_B = B.drop(columns='pv_measurement')\n",
    "y_B = B['pv_measurement']\n",
    "X_C = C.drop(columns='pv_measurement')\n",
    "y_C = C['pv_measurement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34085, 17)\n",
      "(720, 17)\n"
     ]
    }
   ],
   "source": [
    "# Inspect data\n",
    "print(X_A.shape)\n",
    "print(test_A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mae_objective(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom objective function for XGBoost.\n",
    "    Focuses on minimizing the MAE while penalizing under-predictions 1.3 times more than over-predictions.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array): The true values.\n",
    "    y_pred (array): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    grad (array): The gradient.\n",
    "    hess (array): The Hessian (second derivative).\n",
    "    \"\"\"\n",
    "    # Calculate the residual (error)\n",
    "    residual = y_pred - y_true\n",
    "\n",
    "    # Define the factor for under-prediction penalty\n",
    "    under_prediction_factor = 1.3\n",
    "\n",
    "    # Gradient: 1 or -1 multiplied by the under_prediction_factor for under-predictions\n",
    "    grad = np.where(residual < 0, -under_prediction_factor, 1)\n",
    "\n",
    "    # Hessian: Set to a small constant value since the second derivative of MAE is zero\n",
    "    # (This is a common practice for handling MAE in gradient boosting)\n",
    "    hess = np.ones_like(y_pred) * 0.1\n",
    "\n",
    "    return grad, hess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize the models\n",
    "parameters_A = {\n",
    "    'colsample_bytree': 0.8, \n",
    "    'gamma': 0.8, \n",
    "    'learning_rate': 0.008, \n",
    "    'max_depth': 20, \n",
    "    'min_child_weight': 10, \n",
    "    'n_estimators': 1000, \n",
    "    'reg_alpha': 1, \n",
    "    'reg_lambda': 3, \n",
    "    'subsample': 0.912,\n",
    "    'random_state': 0, \n",
    "    'booster': 'gbtree',\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "parameters_B = {\n",
    "    'colsample_bytree': 0.8, \n",
    "    'gamma': 0.8, \n",
    "    'learning_rate': 0.008, \n",
    "    'max_depth': 20, \n",
    "    'min_child_weight': 10, \n",
    "    'n_estimators': 1000, \n",
    "    'reg_alpha': 1, \n",
    "    'reg_lambda': 3, \n",
    "    'subsample': 0.912,\n",
    "    'random_state': 0, \n",
    "    'booster': 'gbtree',\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "parameters_C = {\n",
    "    'colsample_bytree': 0.8, \n",
    "    'gamma': 0.8, \n",
    "    'learning_rate': 0.008, \n",
    "    'max_depth': 20, \n",
    "    'min_child_weight': 10, \n",
    "    'n_estimators': 1000, \n",
    "    'reg_alpha': 1, \n",
    "    'reg_lambda': 3, \n",
    "    'subsample': 0.912,\n",
    "    'random_state': 0, \n",
    "    'booster': 'gbtree',\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "model_A = xgb.XGBRegressor(**parameters_A)\n",
    "model_B = xgb.XGBRegressor(**parameters_B)\n",
    "model_C = xgb.XGBRegressor(**parameters_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=0.8, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.008, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=20, max_leaves=None,\n",
       "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=-1, num_parallel_tree=None,\n",
       "             predictor=None, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=0.8, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.008, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=20, max_leaves=None,\n",
       "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=-1, num_parallel_tree=None,\n",
       "             predictor=None, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=0.8, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.008, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=20, max_leaves=None,\n",
       "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=-1, num_parallel_tree=None,\n",
       "             predictor=None, random_state=0, ...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the models, verbose=False\n",
    "model_A.fit(\n",
    "    X=X_A, y=y_A,\n",
    "    eval_metric='mae',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model_B.fit(\n",
    "    X=X_B, y=y_B,\n",
    "    eval_metric='mae',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model_C.fit(\n",
    "    X=X_C, y=y_C,\n",
    "    eval_metric='mae',\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 total_radiation: 0.5771934390068054\n",
      "1 clear_sky_rad:W: 0.15224255621433258\n",
      "2 effective_cloud_cover:p: 0.03957810252904892\n",
      "3 snow_accumulation: 0.034548476338386536\n",
      "4 sun_elevation:d: 0.03267226368188858\n",
      "5 rain_water:kgm2: 0.02706042304635048\n",
      "6 total_cloud_cover:p: 0.01868657022714615\n",
      "7 sun_azimuth:d: 0.016988426446914673\n",
      "8 month: 0.015764674171805382\n",
      "9 hour: 0.013749673962593079\n",
      "10 year: 0.013071900233626366\n",
      "11 average_wind_speed: 0.012946315109729767\n",
      "12 t_1000hPa:C: 0.012570992112159729\n",
      "13 absolute_humidity_2m:gm3: 0.01239833701401949\n",
      "14 temp_dewpoint_diff: 0.011018941178917885\n",
      "15 super_cooled_liquid_water:kgm2: 0.0094391955062747\n",
      "16 dew_or_rime:idx: 6.97435243637301e-05\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "feature_importances = model_A.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': list(X_A.columns), 'importance': feature_importances}).sort_values('importance', ascending = False)\n",
    "\n",
    "# Print feature importance\n",
    "for i in range(feature_importances.shape[0]):\n",
    "    print(f\"{i} {feature_importances.iloc[i, 0]}: {feature_importances.iloc[i, 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to xgb_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "\n",
    "output_file = 'xgb_submission.csv'\n",
    "\n",
    "pred_A = model_A.predict(test_A)\n",
    "pred_B = model_B.predict(test_B)\n",
    "pred_C = model_C.predict(test_C)\n",
    "\n",
    "pred_A = np.clip(pred_A, 0, None)\n",
    "pred_B = np.clip(pred_B, 0, None)\n",
    "pred_C = np.clip(pred_C, 0, None)\n",
    "\n",
    "# Concatenate predictions\n",
    "predictions = np.concatenate([pred_A, pred_B, pred_C])\n",
    "\n",
    "# Create an id array\n",
    "ids = np.arange(0, len(predictions))\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'prediction': predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Submission saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDT4173-MPC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
