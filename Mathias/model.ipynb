{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prototyping\n",
    "\n",
    "Comparing distributions between the observed and estimated weather. We have to use the label as a brigde for comparing the estimated and observed weather, because we don't have data of these in the same time period, and can therefore not compare them directly. The plan is to train two models, one on the estimated weather and one on the observed. If the model trained on the observed weather works fine for the labels contained in the estimated time-period and vice versa, it implies that the weather predictions are accurate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_target_A = pd.read_parquet('../data/A/train_targets.parquet')\n",
    "x_train_obs_A = pd.read_parquet('../data/A/X_train_observed.parquet')\n",
    "x_train_est_A = pd.read_parquet('../data/A/X_train_estimated.parquet')\n",
    "\n",
    "x_target_B = pd.read_parquet('../data/B/train_targets.parquet')\n",
    "x_train_obs_B = pd.read_parquet('../data/B/X_train_observed.parquet')\n",
    "x_train_est_B = pd.read_parquet('../data/B/X_train_estimated.parquet')\n",
    "\n",
    "x_target_C = pd.read_parquet('../data/C/train_targets.parquet')\n",
    "x_train_obs_C = pd.read_parquet('../data/C/X_train_observed.parquet')\n",
    "x_train_est_C = pd.read_parquet('../data/C/X_train_estimated.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location A obs shape: (29667, 9)\n",
      "Location A est shape: (182, 9)\n",
      "Location B obs shape: (29218, 9)\n",
      "Location B est shape: (150, 9)\n",
      "Location C obs shape: (23141, 9)\n",
      "Location C est shape: (121, 9)\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "def keep_columns(df, columns):\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n",
    "columns = [ 'time', 'clear_sky_rad:W', 'clear_sky_energy_1h:J', 'sun_elevation:d', 'is_day:idx', 'direct_rad_1h:J',\n",
    "            'pv_measurement', 'diffuse_rad_1h:J', 'pressure_100m:hPa' ]\n",
    "\n",
    "\n",
    "# Location A\n",
    "x_train_obs_A_resampled = x_train_obs_A.set_index('date_forecast').resample('1H').mean()\n",
    "x_train_est_A_resampled = x_train_est_A.set_index('date_calc').resample('1H').mean()\n",
    "\n",
    "split_value = x_train_est_A['date_forecast'].iloc[0]\n",
    "split_index = x_target_A[x_target_A['time'] == split_value].index[0]\n",
    "\n",
    "x_target_obs_A = x_target_A.iloc[:split_index]\n",
    "x_target_est_A = x_target_A.iloc[split_index:]\n",
    "\n",
    "x_train_obs_A_resampled = x_train_obs_A_resampled.merge(x_target_obs_A, left_index=True, right_on='time')\n",
    "x_train_est_A_resampled = x_train_est_A_resampled.merge(x_target_est_A, left_index=True, right_on='time')\n",
    "\n",
    "x_train_obs_A_resampled = keep_columns(x_train_obs_A_resampled, columns)\n",
    "x_train_est_A_resampled = keep_columns(x_train_est_A_resampled, columns)\n",
    "\n",
    "x_train_obs_A_resampled = x_train_obs_A_resampled.dropna()\n",
    "x_train_est_A_resampled = x_train_est_A_resampled.dropna()\n",
    "\n",
    "# Location B\n",
    "x_train_obs_B_resampled = x_train_obs_B.set_index('date_forecast').resample('1H').mean()\n",
    "x_train_est_B_resampled = x_train_est_B.set_index('date_calc').resample('1H').mean()\n",
    "\n",
    "split_value = x_train_est_B['date_forecast'].iloc[0]\n",
    "split_index = x_target_B[x_target_B['time'] == split_value].index[0]\n",
    "\n",
    "x_target_obs_B = x_target_B.iloc[:split_index]\n",
    "x_target_est_B = x_target_B.iloc[split_index:]\n",
    "\n",
    "x_train_obs_B_resampled = x_train_obs_B_resampled.merge(x_target_obs_B, left_index=True, right_on='time')\n",
    "x_train_est_B_resampled = x_train_est_B_resampled.merge(x_target_est_B, left_index=True, right_on='time')\n",
    "\n",
    "x_train_obs_B_resampled = keep_columns(x_train_obs_B_resampled, columns)\n",
    "x_train_est_B_resampled = keep_columns(x_train_est_B_resampled, columns)\n",
    "\n",
    "x_train_obs_B_resampled = x_train_obs_B_resampled.dropna()\n",
    "x_train_est_B_resampled = x_train_est_B_resampled.dropna()\n",
    "\n",
    "# Location C\n",
    "x_train_obs_C_resampled = x_train_obs_C.set_index('date_forecast').resample('1H').mean()\n",
    "x_train_est_C_resampled = x_train_est_C.set_index('date_calc').resample('1H').mean()\n",
    "\n",
    "split_value = x_train_est_C['date_forecast'].iloc[0]\n",
    "split_index = x_target_C[x_target_C['time'] == split_value].index[0]\n",
    "\n",
    "x_target_obs_C = x_target_C.iloc[:split_index]\n",
    "x_target_est_C = x_target_C.iloc[split_index:]\n",
    "\n",
    "x_train_obs_C_resampled = x_train_obs_C_resampled.merge(x_target_obs_C, left_index=True, right_on='time')\n",
    "x_train_est_C_resampled = x_train_est_C_resampled.merge(x_target_est_C, left_index=True, right_on='time')\n",
    "\n",
    "x_train_obs_C_resampled = keep_columns(x_train_obs_C_resampled, columns)\n",
    "x_train_est_C_resampled = keep_columns(x_train_est_C_resampled, columns)\n",
    "\n",
    "x_train_obs_C_resampled = x_train_obs_C_resampled.dropna()\n",
    "x_train_est_C_resampled = x_train_est_C_resampled.dropna()\n",
    "\n",
    "print(f'Location A obs shape: {x_train_obs_A_resampled.shape}')\n",
    "print(f'Location A est shape: {x_train_est_A_resampled.shape}')\n",
    "print(f'Location B obs shape: {x_train_obs_B_resampled.shape}')\n",
    "print(f'Location B est shape: {x_train_est_B_resampled.shape}')\n",
    "print(f'Location C obs shape: {x_train_obs_C_resampled.shape}')\n",
    "print(f'Location C est shape: {x_train_est_C_resampled.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Linear Regression at Location A:\n",
      "Mean Absolute Error (MAE): 424.27\n",
      "R-squared: 0.34\n",
      "--------------------------------------------------\n",
      "Performance for Random Forest at Location A:\n",
      "Mean Absolute Error (MAE): 418.33\n",
      "R-squared: 0.48\n",
      "--------------------------------------------------\n",
      "Performance for XGBoost at Location A:\n",
      "Mean Absolute Error (MAE): 604.33\n",
      "R-squared: -0.36\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_performance(y_true, y_pred, model_name, location):\n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Performance for {model_name} at {location}:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"R-squared: {r2:.2f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Splitting data into features and target for Location A\n",
    "X_train_A = x_train_obs_A_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_train_A = x_train_obs_A_resampled['pv_measurement']\n",
    "\n",
    "X_test_A = x_train_est_A_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_test_A = x_train_est_A_resampled['pv_measurement']\n",
    "\n",
    "# Linear Regression for Location A\n",
    "lr_A = LinearRegression()\n",
    "lr_A.fit(X_train_A, y_train_A)\n",
    "lr_pred_A = lr_A.predict(X_test_A)\n",
    "evaluate_model_performance(y_test_A, lr_pred_A, \"Linear Regression\", \"Location A\")\n",
    "\n",
    "# Random Forest for Location A\n",
    "rf_A = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=0)\n",
    "rf_A.fit(X_train_A, y_train_A)\n",
    "rf_pred_A = rf_A.predict(X_test_A)\n",
    "evaluate_model_performance(y_test_A, rf_pred_A, \"Random Forest\", \"Location A\")\n",
    "\n",
    "# XGBoost for Location A\n",
    "xg_reg_A = xgb.XGBRegressor(objective ='reg:absoluteerror', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "xg_reg_A.fit(X_train_A, y_train_A)\n",
    "xg_pred_A = xg_reg_A.predict(X_test_A)\n",
    "evaluate_model_performance(y_test_A, xg_pred_A, \"XGBoost\", \"Location A\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Linear Regression at Location B:\n",
      "Mean Absolute Error (MAE): 55.22\n",
      "R-squared: 0.49\n",
      "--------------------------------------------------\n",
      "Performance for Random Forest at Location B:\n",
      "Mean Absolute Error (MAE): 70.57\n",
      "R-squared: 0.05\n",
      "--------------------------------------------------\n",
      "Performance for XGBoost at Location B:\n",
      "Mean Absolute Error (MAE): 81.01\n",
      "R-squared: -0.31\n",
      "--------------------------------------------------\n",
      "Performance for Linear Regression at Location C:\n",
      "Mean Absolute Error (MAE): 34.07\n",
      "R-squared: 0.06\n",
      "--------------------------------------------------\n",
      "Performance for Random Forest at Location C:\n",
      "Mean Absolute Error (MAE): 23.19\n",
      "R-squared: 0.39\n",
      "--------------------------------------------------\n",
      "Performance for XGBoost at Location C:\n",
      "Mean Absolute Error (MAE): 28.85\n",
      "R-squared: -0.18\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Location B\n",
    "# Splitting data into features and target for Location B\n",
    "X_train_B = x_train_obs_B_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_train_B = x_train_obs_B_resampled['pv_measurement']\n",
    "\n",
    "X_test_B = x_train_est_B_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_test_B = x_train_est_B_resampled['pv_measurement']\n",
    "\n",
    "# Linear Regression for Location B\n",
    "lr_B = LinearRegression()\n",
    "lr_B.fit(X_train_B, y_train_B)\n",
    "lr_pred_B = lr_B.predict(X_test_B)\n",
    "evaluate_model_performance(y_test_B, lr_pred_B, \"Linear Regression\", \"Location B\")\n",
    "\n",
    "# Random Forest for Location B\n",
    "rf_B = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=0)\n",
    "rf_B.fit(X_train_B, y_train_B)\n",
    "rf_pred_B = rf_B.predict(X_test_B)\n",
    "evaluate_model_performance(y_test_B, rf_pred_B, \"Random Forest\", \"Location B\")\n",
    "\n",
    "# XGBoost for Location B\n",
    "xg_reg_B = xgb.XGBRegressor(objective ='reg:absoluteerror', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "xg_reg_B.fit(X_train_B, y_train_B)\n",
    "xg_pred_B = xg_reg_B.predict(X_test_B)\n",
    "evaluate_model_performance(y_test_B, xg_pred_B, \"XGBoost\", \"Location B\")\n",
    "\n",
    "# Location C\n",
    "# Splitting data into features and target for Location C\n",
    "X_train_C = x_train_obs_C_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_train_C = x_train_obs_C_resampled['pv_measurement']\n",
    "\n",
    "X_test_C = x_train_est_C_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_test_C = x_train_est_C_resampled['pv_measurement']\n",
    "\n",
    "# Linear Regression for Location C\n",
    "lr_C = LinearRegression()\n",
    "lr_C.fit(X_train_C, y_train_C)\n",
    "lr_pred_C = lr_C.predict(X_test_C)\n",
    "evaluate_model_performance(y_test_C, lr_pred_C, \"Linear Regression\", \"Location C\")\n",
    "\n",
    "# Random Forest for Location C\n",
    "rf_C = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=0)\n",
    "rf_C.fit(X_train_C, y_train_C)\n",
    "rf_pred_C = rf_C.predict(X_test_C)\n",
    "evaluate_model_performance(y_test_C, rf_pred_C, \"Random Forest\", \"Location C\")\n",
    "\n",
    "# XGBoost for Location C\n",
    "xg_reg_C = xgb.XGBRegressor(objective ='reg:absoluteerror', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "xg_reg_C.fit(X_train_C, y_train_C)\n",
    "xg_pred_C = xg_reg_C.predict(X_test_C)\n",
    "evaluate_model_performance(y_test_C, xg_pred_C, \"XGBoost\", \"Location C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv')\n",
    "x_test_est_A = pd.read_parquet('../data/A/X_test_estimated.parquet')\n",
    "x_test_est_B = pd.read_parquet('../data/B/X_test_estimated.parquet')\n",
    "x_test_est_C = pd.read_parquet('../data/C/X_test_estimated.parquet')\n",
    "\n",
    "def keep_columns(df, columns):\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n",
    "columns = [ 'clear_sky_rad:W', 'clear_sky_energy_1h:J', 'sun_elevation:d', 'is_day:idx', 'direct_rad_1h:J',\n",
    "            'diffuse_rad_1h:J', 'pressure_100m:hPa', 'is_in_shadow:idx', 't_1000hPa:K', 'effective_cloud_cover:p' ]\n",
    "\n",
    "# Location A\n",
    "x_test_est_A_resampled = x_test_est_A.set_index('date_forecast').resample('1H').mean()\n",
    "x_test_est_A_resampled = keep_columns(x_test_est_A_resampled, columns)\n",
    "x_test_est_A_resampled = x_test_est_A_resampled.dropna()\n",
    "\n",
    "# Location B\n",
    "x_test_est_B_resampled = x_test_est_B.set_index('date_forecast').resample('1H').mean()\n",
    "x_test_est_B_resampled = keep_columns(x_test_est_B_resampled, columns)\n",
    "x_test_est_B_resampled = x_test_est_B_resampled.dropna()\n",
    "\n",
    "# Location C\n",
    "x_test_est_C_resampled = x_test_est_C.set_index('date_forecast').resample('1H').mean()\n",
    "x_test_est_C_resampled = keep_columns(x_test_est_C_resampled, columns)\n",
    "x_test_est_C_resampled = x_test_est_C_resampled.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_A = rf_A.predict(x_test_est_A_resampled)\n",
    "y_pred_B = rf_B.predict(x_test_est_B_resampled)\n",
    "y_pred_C = rf_C.predict(x_test_est_C_resampled)\n",
    "\n",
    "# Convert predictions to Pandas Series\n",
    "pred_series_A = pd.Series(y_pred_A, name=\"prediction\")\n",
    "pred_series_B = pd.Series(y_pred_B, name=\"prediction\")\n",
    "pred_series_C = pd.Series(y_pred_C, name=\"prediction\")\n",
    "\n",
    "# Concatenate the series\n",
    "all_predictions = pd.concat([pred_series_A, pred_series_B, pred_series_C], ignore_index=True)\n",
    "\n",
    "# Create an 'id' column\n",
    "all_predictions = all_predictions.reset_index()\n",
    "all_predictions.rename(columns={'index': 'id'}, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "all_predictions.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on all data\n",
    "\n",
    "# Location A\n",
    "X_train_A = x_train_obs_A_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_train_A = x_train_obs_A_resampled['pv_measurement']\n",
    "\n",
    "X_test_A = x_train_est_A_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_test_A = x_train_est_A_resampled['pv_measurement']\n",
    "\n",
    "X_A = pd.concat([X_train_A, X_test_A])\n",
    "y_A = pd.concat([y_train_A, y_test_A])\n",
    "\n",
    "# Location B\n",
    "X_train_B = x_train_obs_B_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_train_B = x_train_obs_B_resampled['pv_measurement']\n",
    "\n",
    "X_test_B = x_train_est_B_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_test_B = x_train_est_B_resampled['pv_measurement']\n",
    "\n",
    "X_B = pd.concat([X_train_B, X_test_B])\n",
    "y_B = pd.concat([y_train_B, y_test_B])\n",
    "\n",
    "# Location C\n",
    "X_train_C = x_train_obs_C_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_train_C = x_train_obs_C_resampled['pv_measurement']\n",
    "\n",
    "X_test_C = x_train_est_C_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_test_C = x_train_est_C_resampled['pv_measurement']\n",
    "\n",
    "X_C = pd.concat([X_train_C, X_test_C])\n",
    "y_C = pd.concat([y_train_C, y_test_C])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding optimal random forest hyperparameters\n",
    "# Define the hyperparameters and their possible values\n",
    "# param_dist = {\n",
    "#     'n_estimators': [10, 50, 100, 200, 500],\n",
    "#     'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# # Initialize the random search\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     RandomForestRegressor(random_state=0),\n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=100,\n",
    "#     cv=3,\n",
    "#     verbose=2,\n",
    "#     random_state=0,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # Fit the random search model\n",
    "# random_search.fit(X_A, y_A)\n",
    "# random_search.fit(X_B, y_B)\n",
    "# random_search.fit(X_C, y_C)\n",
    "\n",
    "# # Get the best parameters\n",
    "# best_params_A = random_search.best_params_\n",
    "# best_params_B = random_search.best_params_\n",
    "# best_params_C = random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Location A: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 10, 'bootstrap': True}\n",
      "Best parameters for Location B: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 10, 'bootstrap': True}\n",
      "Best parameters for Location C: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 10, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters for Location A: {best_params_A}\")\n",
    "print(f\"Best parameters for Location B: {best_params_B}\")\n",
    "print(f\"Best parameters for Location C: {best_params_C}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, max_features=&#x27;log2&#x27;, n_estimators=1000,\n",
       "                      random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, max_features=&#x27;log2&#x27;, n_estimators=1000,\n",
       "                      random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10, max_features='log2', n_estimators=1000,\n",
       "                      random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on all data\n",
    "# Best parameters from algorithm\n",
    "# n_estimators=500, min_samples_split=2, min_samples_leaf=1, max_features='log2', max_depth=10, bootstrap=True, random_state=0\n",
    "\n",
    "# Location A\n",
    "X_train_A = x_train_obs_A_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_train_A = x_train_obs_A_resampled['pv_measurement']\n",
    "\n",
    "X_test_A = x_train_est_A_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_test_A = x_train_est_A_resampled['pv_measurement']\n",
    "\n",
    "X_A = pd.concat([X_train_A, X_test_A])\n",
    "y_A = pd.concat([y_train_A, y_test_A])\n",
    "\n",
    "# Random Forest for Location A\n",
    "rf_A = RandomForestRegressor(n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features='log2', max_depth=10, bootstrap=True, random_state=0)\n",
    "rf_A.fit(X_A, y_A)\n",
    "\n",
    "# Location B\n",
    "X_train_B = x_train_obs_B_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_train_B = x_train_obs_B_resampled['pv_measurement']\n",
    "\n",
    "X_test_B = x_train_est_B_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_test_B = x_train_est_B_resampled['pv_measurement']\n",
    "\n",
    "X_B = pd.concat([X_train_B, X_test_B])\n",
    "y_B = pd.concat([y_train_B, y_test_B])\n",
    "\n",
    "# Random Forest for Location B\n",
    "rf_B = RandomForestRegressor(n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features='log2', max_depth=10, bootstrap=True, random_state=0)\n",
    "rf_B.fit(X_B, y_B)\n",
    "\n",
    "# Location C\n",
    "X_train_C = x_train_obs_C_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_train_C = x_train_obs_C_resampled['pv_measurement']\n",
    "\n",
    "X_test_C = x_train_est_C_resampled.drop(columns=['time', 'pv_measurement'])\n",
    "y_test_C = x_train_est_C_resampled['pv_measurement']\n",
    "\n",
    "X_C = pd.concat([X_train_C, X_test_C])\n",
    "y_C = pd.concat([y_train_C, y_test_C])\n",
    "\n",
    "# Random Forest for Location C\n",
    "rf_C = RandomForestRegressor(n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features='log2', max_depth=10, bootstrap=True, random_state=0)\n",
    "rf_C.fit(X_C, y_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Stacked Regressor at Location A:\n",
      "Mean Absolute Error (MAE): 223.30\n",
      "R-squared: 0.84\n",
      "--------------------------------------------------\n",
      "Performance for Stacked Regressor at Location B:\n",
      "Mean Absolute Error (MAE): 46.91\n",
      "R-squared: 0.79\n",
      "--------------------------------------------------\n",
      "Performance for Stacked Regressor at Location C:\n",
      "Mean Absolute Error (MAE): 25.63\n",
      "R-squared: 0.88\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Stacking models into meta modell \n",
    "\n",
    "# Split your training data into a new training set and a validation set for Location A\n",
    "X_train_A_new, X_val_A, y_train_A_new, y_val_A = train_test_split(X_train_A, y_train_A, test_size=0.2, random_state=42)\n",
    "X_train_B_new, X_val_B, y_train_B_new, y_val_B = train_test_split(X_train_B, y_train_B, test_size=0.2, random_state=42)\n",
    "X_train_C_new, X_val_C, y_train_C_new, y_val_C = train_test_split(X_train_C, y_train_C, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the stacking regressor for Location A\n",
    "stacked_A = StackingCVRegressor(regressors=(rf_A, lr_A, xg_reg_A),\n",
    "                                meta_regressor=LinearRegression(),\n",
    "                                use_features_in_secondary=True)\n",
    "\n",
    "stacked_B = StackingCVRegressor(regressors=(rf_B, lr_B, xg_reg_B),\n",
    "                                meta_regressor=LinearRegression(),\n",
    "                                use_features_in_secondary=True)\n",
    "\n",
    "stacked_C = StackingCVRegressor(regressors=(rf_C, lr_C, xg_reg_C),\n",
    "                                meta_regressor=LinearRegression(),\n",
    "                                use_features_in_secondary=True)\n",
    "\n",
    "# Train the stacking regressor on the new training data\n",
    "stacked_A.fit(X_train_A_new.values, y_train_A_new.values)\n",
    "stacked_B.fit(X_train_B_new.values, y_train_B_new.values)\n",
    "stacked_C.fit(X_train_C_new.values, y_train_C_new.values)\n",
    "\n",
    "# Predictions\n",
    "stacked_pred_A = stacked_A.predict(X_val_A.values)\n",
    "stacked_pred_B = stacked_B.predict(X_val_B.values)\n",
    "stacked_pred_C = stacked_C.predict(X_val_C.values)\n",
    "evaluate_model_performance(y_val_A, stacked_pred_A, \"Stacked Regressor\", \"Location A\")\n",
    "evaluate_model_performance(y_val_B, stacked_pred_B, \"Stacked Regressor\", \"Location B\")\n",
    "evaluate_model_performance(y_val_C, stacked_pred_C, \"Stacked Regressor\", \"Location C\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathiasotnes/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mathiasotnes/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mathiasotnes/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mathiasotnes/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mathiasotnes/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/mathiasotnes/anaconda3/envs/TDT4173-MPC/lib/python3.11/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred_A = stacked_A.predict(x_test_est_A_resampled.drop(columns=['is_in_shadow:idx', 't_1000hPa:K', 'effective_cloud_cover:p']))\n",
    "y_pred_B = stacked_B.predict(x_test_est_B_resampled.drop(columns=['is_in_shadow:idx', 't_1000hPa:K', 'effective_cloud_cover:p']))\n",
    "y_pred_C = stacked_C.predict(x_test_est_C_resampled.drop(columns=['is_in_shadow:idx', 't_1000hPa:K', 'effective_cloud_cover:p']))\n",
    "\n",
    "# Convert predictions to Pandas Series\n",
    "pred_series_A = pd.Series(y_pred_A, name=\"prediction\")\n",
    "pred_series_B = pd.Series(y_pred_B, name=\"prediction\")\n",
    "pred_series_C = pd.Series(y_pred_C, name=\"prediction\")\n",
    "\n",
    "# Concatenate the series\n",
    "all_predictions = pd.concat([pred_series_A, pred_series_B, pred_series_C], ignore_index=True)\n",
    "\n",
    "# Create an 'id' column\n",
    "all_predictions = all_predictions.reset_index()\n",
    "all_predictions.rename(columns={'index': 'id'}, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "all_predictions.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDT4173-MPC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
