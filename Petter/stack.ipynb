{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # for the progress bar\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(pred_A, pred_B, pred_C, output_file=\"submission.csv\"):\n",
    "    \"\"\"\n",
    "    Create a Kaggle submission file.\n",
    "\n",
    "    Parameters:\n",
    "    - pred_A, pred_B, pred_C: Arrays containing predictions.\n",
    "    - output_file: Name of the output CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - None. Writes the submission to a CSV file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Concatenate predictions\n",
    "    predictions = np.concatenate([pred_A, pred_B, pred_C])\n",
    "\n",
    "    # Create an id array\n",
    "    ids = np.arange(0, len(predictions))\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'prediction': predictions\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Submission saved to {output_file}\")\n",
    "\n",
    "\n",
    "# Read in the data\n",
    "data_path = '../preprocessing/data'\n",
    "obs_A = pd.read_parquet(f'{data_path}/obs_A.parquet')\n",
    "est_A = pd.read_parquet(f'{data_path}/est_A.parquet')\n",
    "obs_B = pd.read_parquet(f'{data_path}/obs_B.parquet')\n",
    "est_B = pd.read_parquet(f'{data_path}/est_B.parquet')\n",
    "obs_C = pd.read_parquet(f'{data_path}/obs_C.parquet')\n",
    "est_C = pd.read_parquet(f'{data_path}/est_C.parquet')\n",
    "\n",
    "test_A = pd.read_parquet(f'{data_path}/test_A.parquet').dropna()\n",
    "test_B = pd.read_parquet(f'{data_path}/test_B.parquet').dropna()\n",
    "test_C = pd.read_parquet(f'{data_path}/test_C.parquet').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pv_measurement', 'absolute_humidity_2m:gm3', 'air_density_2m:kgm3',\n",
       "       'clear_sky_rad:W', 'dew_point_2m:K', 'diffuse_rad:W', 'direct_rad:W',\n",
       "       'effective_cloud_cover:p', 'msl_pressure:hPa', 'pressure_100m:hPa',\n",
       "       'pressure_50m:hPa', 'relative_humidity_1000hPa:p', 'sfc_pressure:hPa',\n",
       "       'snow_water:kgm2', 'sun_azimuth:d', 'sun_elevation:d', 't_1000hPa:K',\n",
       "       'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms',\n",
       "       'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms', 'clear_sky_energy_1h:J',\n",
       "       'diffuse_rad_1h:J', 'direct_rad_1h:J', 'month', 'year', 'time_of_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_A.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('lr', LinearRegression(n_jobs=-1)),\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, criterion='absolute_error', n_jobs=-1)),\n",
    "    ('ada', AdaBoostRegressor(n_estimators=50)),\n",
    "    ('xgb', XGBRegressor(n_estimators=100, learning_rate=0.1, n_jobs=-1))\n",
    "]\n",
    "\n",
    "final_estimator = RandomForestRegressor(n_estimators=100, criterion='absolute_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = est_A\n",
    "\n",
    "# Split to features and labels\n",
    "X_A = A.drop(columns=['pv_measurement'])\n",
    "y_A = A['pv_measurement']\n",
    "\n",
    "X_train_A, X_test_A, y_train_A, y_test_A = train_test_split(X_A, y_A, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Create StackingRegressor instances\n",
    "stack_A = StackingRegressor(estimators=base_models, final_estimator=final_estimator)\n",
    "\n",
    "# Fit the StackingRegressor on the data\n",
    "stack_A.fit(X_train_A, y_train_A)\n",
    "\n",
    "# Make predictions\n",
    "pred_A = stack_A.predict(test_A)\n",
    "\n",
    "pred_A = np.clip(pred_A, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = est_B\n",
    "\n",
    "# Split to features and labels\n",
    "X_B = B.drop(columns=['pv_measurement'])\n",
    "y_B = B['pv_measurement']\n",
    "\n",
    "X_train_B, X_test_B, y_train_B, y_test_B = train_test_split(X_B, y_B, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Create StackingRegressor instances\n",
    "stack_B = StackingRegressor(estimators=base_models, final_estimator=final_estimator)\n",
    "\n",
    "# Fit the StackingRegressor on the data\n",
    "stack_B.fit(X_train_B, y_train_B)\n",
    "\n",
    "# Make predictions\n",
    "pred_B = stack_B.predict(test_B)\n",
    "\n",
    "pred_B = np.clip(pred_B, 0, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = est_C\n",
    "\n",
    "# Split to features and labels\n",
    "X_C = C.drop(columns=['pv_measurement'])\n",
    "y_C = C['pv_measurement']\n",
    "\n",
    "X_train_C, X_test_C, y_train_C, y_test_C = train_test_split(X_C, y_C, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Create StackingRegressor instances\n",
    "stack_C = StackingRegressor(estimators=base_models, final_estimator=final_estimator)\n",
    "\n",
    "# Fit the StackingRegressor on the data\n",
    "stack_C.fit(X_train_C, y_train_C)\n",
    "\n",
    "# Make predictions\n",
    "pred_C = stack_C.predict(test_C)\n",
    "\n",
    "pred_C = np.clip(pred_C, 0, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to ../submission.csv\n"
     ]
    }
   ],
   "source": [
    "create_submission(pred_A, pred_B, pred_C, output_file=\"../submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDT4173-MPC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
